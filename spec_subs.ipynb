{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/miniconda3/envs/malab/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas.errors import EmptyDataError\n",
    "import requests \n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import re\n",
    "from Bio.Alphabet import IUPAC\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import os, os.path\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup \n",
    "import sklearn.cluster as cluster\n",
    "import sklearn \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "#Chrome Driver imports\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.support.ui import WebDriverWait # available since 2.4.0\n",
    "from selenium.webdriver.support import expected_conditions as EC # available since 2.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared tmp directory\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def create_directory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "def remove_thing(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.remove(path)\n",
    "\n",
    "def empty_directory(path):\n",
    "    for i in glob.glob(os.path.join(path, '*')):\n",
    "        remove_thing(i)\n",
    "\n",
    "def create_run_directory(run_name,MSA=False):\n",
    "    create_directory(run_name)\n",
    "    create_directory(run_name+\"/input\")\n",
    "    if MSA:\n",
    "        create_directory(run_name+\"/MSA_input\")\n",
    "        create_directory(run_name+\"/MSA_output\")\n",
    "    create_directory(run_name+\"/output\")\n",
    "    create_directory(run_name+\"/summary\")\n",
    "    create_directory(run_name+\"/run_params\")\n",
    "\n",
    "def write_run_params_file(config, spec_path, spec_hc):\n",
    "    config_keys = [\"RunName\",\"GenesFile\",\"odb_level\"]\n",
    "    run_name = config[\"RunName\"]\n",
    "    fpath = run_name+\"/run_params/params.txt\"\n",
    "    params_f = open(fpath, 'wt')\n",
    "    for key in config_keys:\n",
    "        val = config[key]\n",
    "        file_line = \"{0}: {1}\\n\".format(key,val)\n",
    "        params_f.write(file_line)\n",
    "    params_f.write(\"species_list: {0}\\n\".format(spec_path))\n",
    "    params_f.write(\"species_hashcode: {0}\\n\".format(spec_hc))\n",
    "    params_f.close()\n",
    "\n",
    "create_directory(\"tmp\")\n",
    "empty_directory('tmp')\n",
    "print(\"Cleared tmp directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "class SequenceDataError(Error):\n",
    "    error_type = \"SequenceDataError\"\n",
    "    def __init__(self,code, message):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "class OrthoDBQueryError(Error):\n",
    "    error_type = \"OrthoDBQueryError\"\n",
    "    def __init__(self, code, message):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "class GeneCardsError(Error):\n",
    "    error_type = \"GeneCardsError\"\n",
    "    def __init__(self, code, message):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "class SequenceAnalysisError(Error):\n",
    "    error_type = \"SequenceAnalysisError\"\n",
    "    def __init__(self, code, message):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "\n",
    "        \n",
    "def write_errors(errors_fpath,gene_name,error):\n",
    "    import os.path\n",
    "    error_type = error.error_type\n",
    "    error_code = error.code \n",
    "    error_msg = error.message\n",
    "    if not os.path.exists(errors_fpath):\n",
    "        errors_f = open(errors_fpath,'wt')\n",
    "        errors_f.write(\"gene\\terror_type\\terror_code\\terror_str\\n\")\n",
    "    else:\n",
    "        errors_df = pd.read_csv(errors_fpath,delimiter='\\t')\n",
    "        if gene_name in errors_df[\"gene\"].unique():\n",
    "            gene_error_df = errors_df.loc[errors_df[\"gene\"]==gene_name,:]\n",
    "            if gene_error_df[\"error_str\"].str.contains(error_msg).any():\n",
    "#                 print(\"Previously stored error:\")\n",
    "                error_row = gene_error_df.loc[gene_error_df[\"error_str\"]==error_msg,:]\n",
    "                gene_name,error_type,error_code,error_msg = error_row.values[0]\n",
    "                print(\"{0}\\t{1}\\t{2}\\t{3}\".format(gene_name,error_type,error_code,error_msg))\n",
    "                return\n",
    "    errors_f = open(errors_fpath,'at')\n",
    "    fline = \"{0}\\t{1}\\t{2}\\t{3}\\n\".format(gene_name,error_type,error_code,error_msg)\n",
    "    errors_f.write(fline)\n",
    "    print(fline)\n",
    "    errors_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odb_error = OrthoDBQueryError(0,\"No OrthoDB results for query\")\n",
    "# print(odb_error.error_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config_file=\"config/config.txt\"):\n",
    "    #Parse config text file (INI format) to establish paramters for the run\n",
    "    #config_file should be a path to the config file (\"config/config.txt\" by default)\n",
    "    import configparser\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    return config[\"DEFAULT\"]\n",
    "def parse_genes(genes_path=\"config/genes.txt\"):\n",
    "    #Parses gene file into list of uppercase, whitespace trimmed gene names\n",
    "    gene_flines = open(genes_path).readlines()\n",
    "    genes = [gene.strip().upper() for gene in gene_flines]\n",
    "    return genes\n",
    "def parse_species(species_path=\"config/v10_0_species.txt\"):\n",
    "    #Reads species list from file in config directory. Also returns a hashcode for the list of species used\n",
    "    spec_lines = open(species_path).readlines()\n",
    "    species = [spec.strip() for spec in spec_lines]\n",
    "    concat = \"\"\n",
    "    for spec in species: \n",
    "        concat = concat + spec\n",
    "    hc = np.abs(hash(concat))\n",
    "    return species, hc\n",
    "\n",
    "def odb_tablev9(species_list,table_path=\"odb9v1_raw/odb9v1_species.tab\"):\n",
    "    odb = pd.read_csv(table_path,delimiter=\"\\t\",header=None,names=[\"tax_id\",\"odb_id\",\"spec_name\",\"clustered_genes\",\"ortho_groups\",\"mapping_type\"])\n",
    "    filtered = pd.DataFrame(columns=odb.columns)\n",
    "    for spec in species_list:\n",
    "        row = odb[odb[\"spec_name\"]==spec]\n",
    "        filtered = filtered.append(row)\n",
    "    filtered.drop(columns=[\"clustered_genes\",\"ortho_groups\",\"mapping_type\"],inplace=True)\n",
    "    return filtered\n",
    "def odb_tablev10(species_list,table_path=\"odb10v0/odb10v0_species.tab\"):\n",
    "    \"\"\"odb10v0_species.tab\n",
    "    1.\tNCBI tax id\n",
    "    2.\tOrtho DB individual organism id, based on NCBI tax id\n",
    "    3.\tscientific name inherited from the most relevant NCBI tax id\n",
    "    4.\tgenome asssembly id, when available\n",
    "    5.\ttotal count of clustered genes in this species\n",
    "    6.\ttotal count of the OGs it participates\n",
    "    7.\tmapping type, clustered(C) or mapped(M)\n",
    "    \"\"\"\n",
    "    odb = pd.read_csv(table_path,delimiter=\"\\t\",header=None,names=[\"tax_id\",\"odb_id\",\"spec_name\",\"assembly_id\",\"clustered_genes\",\"ortho_groups\",\"mapping_type\"])\n",
    "#     display(odb)\n",
    "    filtered = pd.DataFrame(columns=odb.columns)\n",
    "    for spec in species_list:\n",
    "        row = odb[odb[\"spec_name\"]==spec]\n",
    "        filtered = filtered.append(row)\n",
    "    filtered.drop(columns=[\"clustered_genes\",\"ortho_groups\",\"mapping_type\"],inplace=True)\n",
    "    return filtered\n",
    "\n",
    "config = parse_config()\n",
    "test_species = config[\"TestSpecies\"]\n",
    "species_path=\"config/v10_0_species.txt\"\n",
    "spec_list, hc = parse_species(species_path)\n",
    "# gene_list = parse_genes(\"config/complexIV_V_genes.txt\")\n",
    "gene_list = parse_genes(config[\"GenesFile\"])\n",
    "tax_table = odb_tablev10(spec_list)\n",
    "run_name = config[\"RunName\"]\n",
    "create_directory(run_name)\n",
    "errors_fpath = run_name+'/summary/errors.tsv'\n",
    "seq_qc_fpath = run_name+'/summary/seq_QC.tsv' \n",
    "DISPLAY_PARAMS = False\n",
    "if DISPLAY_PARAMS:\n",
    "    print(\"Tax table for species list at \"+species_path)\n",
    "    display(tax_table)\n",
    "    print(\"Gene list: \"+str(gene_list))\n",
    "    print(\"Run Name: \"+ run_name)\n",
    "#Verify that species table, gene list, and run_name are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_blos_df():\n",
    "    global aas, blosum62_bg\n",
    "    aas = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V','-']\n",
    "    bg_probs = [0.078, 0.051, 0.041, 0.052, 0.024, 0.034, 0.059, 0.083, 0.025, 0.062, 0.092, 0.056, 0.024, 0.044, 0.043, 0.059, 0.055, 0.014, 0.034, 0.072]#, 0.000001]\n",
    "    blosum62_bgdict = dict(zip(aas,bg_probs))\n",
    "    blosum62_bg = bg_probs\n",
    "    blos_df = pd.DataFrame(index=aas[:-1],columns=aas[:-1])\n",
    "    for pair in blosum62:\n",
    "        val = blosum62[pair]\n",
    "        first, second = pair[0],pair[1]\n",
    "        if first in aas and second in aas:\n",
    "            blos_df.loc[first,second] = val\n",
    "            blos_df.loc[second,first] = val\n",
    "    sim_matrix = blos_df.values\n",
    "    return aas, blosum62_bg, blos_df, sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire input data via OrthoDB API \n",
    "def ODB_query(run_name,gene_name,level_str,spec_str):\n",
    "    \"\"\"Queries OrthoDB via the fasta and tab API for gene_name. \n",
    "    More info: https://www.orthodb.org/orthodb_userguide.html#api\n",
    "    level_str corresponds to the API variable for phylogenetic clade \n",
    "    spec_str corresponds to the taxonomy ids for the list of species from the config folder \n",
    "    \"\"\"\n",
    "    import time, json \n",
    "    from json import JSONDecodeError\n",
    "    #File paths and OrthoDB urls for downloads. NOTE BASE_URL might need updating depending on ODB conventions\n",
    "    BASE_URL = \"https://v101.orthodb.org\"\n",
    "    query_str = \"query={0}\".format(gene_name)\n",
    "    fasta_url = \"{0}/fasta?{1}&{2}&{3}\".format(BASE_URL,query_str,level_str,spec_str)\n",
    "#     print(fasta_url)\n",
    "    fasta_path = \"{0}/input/{1}.fasta\".format(run_name,gene_name)\n",
    "    tsv_url = \"{0}/tab?{1}&{2}&{3}\".format(BASE_URL,query_str,level_str,spec_str)\n",
    "    tsv_path = \"{0}/input/{1}.tsv\".format(run_name,gene_name)\n",
    "    #Obey OrthoDB download restrictions (one request per second) bc you're a good noodle\n",
    "    t1 = time.process_time()\n",
    "    fasta_proc = subprocess.run(args=['wget',fasta_url,'-O',fasta_path])\n",
    "    if (time.process_time()-t1) < 1:\n",
    "        time.sleep(0.5) #Gotta be nice to the orthodb servers or they block you :^( \n",
    "    t1 = time.process_time()\n",
    "    tsv_proc = subprocess.run(args=['wget',tsv_url,'-O',tsv_path])\n",
    "    if (time.process_time()-t1) < 1:\n",
    "        time.sleep(0.5)\n",
    "    try: \n",
    "        #JSON format returned if no results for query string - try opening downloaded data as JSON, if\n",
    "        #successful, raise an OrthoDBQueryError\n",
    "        tsv_json = json.load(open(tsv_path))\n",
    "        os.remove(fasta_path)\n",
    "        os.remove(tsv_path)\n",
    "        raise OrthoDBQueryError(0,\"No OrthoDB results for query\")\n",
    "    except JSONDecodeError:\n",
    "        #Check if html syntax present in file; if not, query was successful and run_name/input should now\n",
    "            #have ODB formatted .fasta and .tsv files\n",
    "        file_txt = \"\"\n",
    "        with open(fasta_path,\"rt\") as fasta_f:\n",
    "            for i in range(10):\n",
    "                file_txt = file_txt + fasta_f.readline()\n",
    "            if bool(BeautifulSoup(file_txt,\"html.parser\").find()):\n",
    "                os.remove(fasta_path)\n",
    "                os.remove(tsv_path)\n",
    "                raise OrthoDBQueryError(1,\"OrthoDB search yielded too many clusters\")\n",
    "            #If no OrthoDBQueryError is raised, download was successful (no further action needed)\n",
    "    \n",
    "def download_input_data(gene_list,tax_table,config):\n",
    "    \"\"\"Queries OrthoDB for all entries in gene list (logs failed searches into errors_fpath), using species \n",
    "    list from tax_table and taxonomy level provided in config directory.\"\"\"\n",
    "    tax_ids = tax_table[\"tax_id\"].values.astype(str)\n",
    "    spec_str = \"species=\"+\",\".join(tax_ids)\n",
    "    level_str = \"level=\"+str(config[\"odb_level\"])\n",
    "    failed_queries = []\n",
    "    run_name = config[\"RunName\"]\n",
    "    errors_fpath = run_name+\"/summary/errors.tsv\"\n",
    "    if os.path.exists(errors_fpath):\n",
    "        errors_df = pd.read_csv(errors_fpath,delimiter='\\t')\n",
    "        ODB_errors_df = errors_df.loc[errors_df[\"error_type\"]==\"OrthoDBQueryError\",:]\n",
    "        check_error_file = True\n",
    "    else:\n",
    "        check_error_file = False\n",
    "    for gene_name in gene_list: \n",
    "        fasta_path = \"{0}/input/{1}.fasta\".format(run_name,gene_name)\n",
    "        if config.getboolean(\"OverwriteInput\") or not os.path.exists(fasta_path):\n",
    "            if check_error_file and gene_name in ODB_errors_df[\"gene\"].unique():#ODB_errors_df[\"gene\"].str.match(gene_name).any():\n",
    "                ODB_error_row = ODB_errors_df.loc[ODB_errors_df[\"gene\"]==gene_name,:]\n",
    "                genename,error_type,error_code,error_msg = ODB_error_row.values[0]\n",
    "                print(\"{0}\\t{1}\\t{2}\\t{3}\".format(genename,error_type,error_code,error_msg))\n",
    "                failed_queries.append(gene_name)\n",
    "            else:\n",
    "                try:\n",
    "                    ODB_query(run_name,gene_name,level_str,spec_str)\n",
    "                except OrthoDBQueryError as odb_error:\n",
    "                    failed_queries.append(gene_name)\n",
    "                    write_errors(errors_fpath,gene_name,odb_error)\n",
    "\n",
    "    print(\"Input queries downloaded.\")\n",
    "    valid_queries = [gene for gene in gene_list if gene not in failed_queries]\n",
    "    return valid_queries, failed_queries\n",
    "\n",
    "#Error Testing for bad OrthoDB queries\n",
    "gene_list = parse_genes(config[\"GenesFile\"])\n",
    "# valid_searches, failed_queries = download_input_data(gene_list,tax_table,config) \n",
    "# testset1 = [\"CDC42\",\"OLFR710A\",\"ATP5G1\",\"CBR3-AS1\"]\n",
    "# download_input_data(testset1,tax_table,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_odb_field(field):\n",
    "    \"\"\"Remove spaces, commas, and capitalization from alias/ odb fields to search for string matches.\n",
    "    If field is empty (np.nan), return empty string\"\"\"\n",
    "    if(type(field)) == str:\n",
    "        field = field.replace(\" \",\"\")\n",
    "        field = field.replace(\",\",\"\")\n",
    "        field = field.replace(\"\\n\",\"\")\n",
    "        return field.lower()\n",
    "    elif type(field) == float and np.isnan(field):\n",
    "        return \"\"\n",
    "    \n",
    "def write_aliases_f(aliases,aliases_fpath):\n",
    "    aliases_f = open(aliases_fpath,'wt')\n",
    "    for a in aliases:\n",
    "        aliases_f.write(a.strip()+'\\n')\n",
    "    aliases_f.close()\n",
    "def download_alias_data(genename):\n",
    "    \"\"\"Queries GeneCards for alias data for genename. Should only be called if aliases_fpath doesn't exist \n",
    "    (ie if query has not been previously run and written to file). Attempts GeneCards query - if genename\n",
    "    leads to a single entry page, pulls aliases from page html. If query leads to a query results page, \n",
    "    checks all linked entries to see if any contain genename. If none do (or other WebDriver issues arise),\n",
    "    raises a GeneCardsError. \n",
    "    \n",
    "    If query was successful (either single result page or successfully chose linked result from query results),\n",
    "    return aliases and gc_name (the gene identifier used by GeneCards). gc_name stored separately since alias html \n",
    "    extraction will miss it otherwise. Also writes alias data to aliases_fpath\n",
    "    \n",
    "    Updated 01/10/2020. If function is consistently failing, check xpath class names against orthodb website\"\"\"\n",
    "    aliases_fpath = \"aliases_data/\"+genename+\"_aliases.txt\"\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\")  \n",
    "    WINDOW_SIZE = \"1920,1080\"\n",
    "    chrome_options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n",
    "    import time \n",
    "#         time.sleep(1.05)\n",
    "#     gene_cards_url = \"https://www.genecards.org/cgi-bin/carddisp.pl?gene=\"+genename.upper()+\\\n",
    "#                       \"&keywords=\"+genename.upper()+\"#aliases_descriptions\"\n",
    "    gene_cards_url = \"https://www.genecards.org/cgi-bin/carddisp.pl?gene={0}\".format(genename.upper())\n",
    "    alias_left_xpath = \"//div[@class='col-xs-12 col-sm-6 gc-double-column-desktop'][1]/ul/li\"\n",
    "    alias_right_xpath = \"//div[@class='col-xs-12 col-sm-6 gc-double-column-desktop'][2]/ul/li\"\n",
    "    alias_single_xpath = \"//div[@class='col-xs-8'][1]/ul/li\"\n",
    "#     elem_xpaths = [alias_left_xpath,alias_right_xpath,alias_single_xpath]\n",
    "    list_xpath = \"//ul[@class='list-unstyled list-spacious']/li\"\n",
    "    elem_xpaths = [list_xpath]\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    driver.get(gene_cards_url)\n",
    "    aliases = []\n",
    "    for xpath in elem_xpaths:\n",
    "        elems = driver.find_elements_by_xpath(xpath)\n",
    "        innerHTMLs = [elem.get_attribute(\"innerHTML\") for elem in elems]\n",
    "        col_aliases = [BeautifulSoup(markup).find(text=True).strip() for markup in innerHTMLs]\n",
    "        aliases.extend(col_aliases)\n",
    "    if len(aliases) > 0:  \n",
    "        #Means genename query to GeneCards autoredirected to a single page - normal aliases scraping\n",
    "        #HTML parsing for GeneCards website - end result is list of trimmed alias strings\n",
    "        gc_re = re.search(\"gene=([A-Z0-9]+)\",gene_cards_url)\n",
    "        gc_name = gc_re.groups()[0].strip()\n",
    "        if gc_name not in aliases:\n",
    "            aliases.insert(0,gc_name)\n",
    "        #Cache aliases to aliases_fpath\n",
    "        write_aliases_f(aliases,aliases_fpath)\n",
    "        driver.quit()\n",
    "        return aliases, gc_name\n",
    "    else: \n",
    "        #Try search results page for genename; raise GeneCardsError if no results or check each page \n",
    "        #for alias matching genename otherwise\n",
    "        query_url = \"https://www.genecards.org/Search/Keyword?queryString={0}\".format(gene_name)\n",
    "        links_xpath = \"//td[@class='gc-gene-symbol gc-highlight symbol-col']/a\"\n",
    "        link_elems = driver.find_elements_by_xpath(links_xpath)\n",
    "        if link_elems: \n",
    "            for elem in links_elems:\n",
    "                elem_href = elem.get_attribute(\"href\")\n",
    "                driver.get(elem_href)\n",
    "                query_url = driver.current_url\n",
    "                elem_gc_name = re.search(\"gene=([A-Z0-9]+)\",query_url).groups()[0].strip()\n",
    "                elem_aliases = []\n",
    "                for xpath in elem_xpaths:\n",
    "                    elems = driver.find_elements_by_xpath(xpath)\n",
    "                    innerHTMLs = [elem.get_attribute(\"innerHTML\") for elem in elems]\n",
    "                    col_aliases = [BeautifulSoup(markup).find(text=True).strip() for markup in innerHTMLs]\n",
    "                    elem_aliases.extend(col_aliases)\n",
    "                if genename in elem_aliases or genename == elem_gc_name:\n",
    "                    #Found query result with genename \n",
    "                    driver.quit()\n",
    "                    if elem_gc_name not in elem_aliases:\n",
    "                        elem_aliases.insert(0,elem_gc_name)\n",
    "                    write_aliases_f(elem_aliases,aliases_fpath)\n",
    "                    return elem_aliases, elem_gc_name\n",
    "        #If either no link_elems (empty search results page), or none correspond to genename:\n",
    "        driver.quit()\n",
    "        raise GeneCardsError(0,\"Could not automatically fetch alias data from GeneCards - consider searching manually\")\n",
    "\n",
    "def find_ref_seqs(genename, tsv_df,errors_fpath):\n",
    "    \"\"\"Returns a list of the orthodb ids of the reference sequences to use for distance/ length pre-filtering\n",
    "    First attempts to find entries for which pub_gene_id is genename (works in most cases)\n",
    "    In the event that none of the orthodb sequences have a pub_gene_id match, uses genecards to find aliases and run\n",
    "    a more comprehensive search of the input for reference sequences to use. GeneCard aliases are saved in text\n",
    "    files in input/aliases. \n",
    "    EDIT: Now uses GeneCard aliases regardless of number of pubgene_id annotated sequences\"\"\" \n",
    "    ref_ids = []\n",
    "    #Go to genecards page for genename, extract information for aliases from the webpage/ html \n",
    "    aliases_fpath = \"aliases_data/\"+genename+\"_aliases.txt\"\n",
    "    \n",
    "    #If file doesn't exist or was improperly downloaded to yield only one line, repeat \n",
    "    #fetching alias names \n",
    "    if (not os.path.exists(aliases_fpath)) or len(open(aliases_fpath,'r').readlines()) == 1:\n",
    "        try: \n",
    "            aliases, gc_name = download_alias_data(genename)\n",
    "            matches = set((genename.upper(),gc_name.upper()))\n",
    "        except GeneCardsError as gc_error:\n",
    "            aliases = [genename]\n",
    "            matches = set((genename.upper(),))\n",
    "            write_errors(errors_fpath,genename,gc_error)\n",
    "    else:\n",
    "        #Read aliases information previously downloaded from GeneCards\n",
    "        aliases_f = open(aliases_fpath,'r')\n",
    "        aliases = aliases_f.readlines()\n",
    "        aliases_f = open(aliases_fpath,'r')\n",
    "        gc_name = aliases_f.readline().strip()\n",
    "        matches = set((genename.upper(),gc_name.upper()))\n",
    "    #Remove spaces, commas, new line chars, and capitalization from alias strings\n",
    "    formatted_aliases = [format_odb_field(alias) for alias in aliases]\n",
    "    #Search fields in search_fields for matches to the alias strings provided by GeneCards\n",
    "    #Iterate tsv_df rows, save all reference ids which have matches \n",
    "    search_fields = [\"pub_gene_id\",\"og_name\",\"description\"]\n",
    "    aliases_pat = \"|\".join(formatted_aliases)\n",
    "    for idx,row in tsv_df.iterrows():\n",
    "#         for field in search_fields:\n",
    "            #Current behavior: exact matches in formatted pub_gene_id, og_name, or description only.\n",
    "            #TODO: Add in partial string matching. Difficulties with distinguishing genenames\n",
    "        for alias in formatted_aliases: \n",
    "            for field in search_fields:\n",
    "                formatted_field = format_odb_field(str(row[field]))\n",
    "                try:\n",
    "                    if re.search(alias,formatted_field):\n",
    "                        if idx not in ref_ids:\n",
    "                            ref_ids.append(idx)#[\"int_prot_id\"])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    #Special regexp characters present in alias \n",
    "                    if alias in formatted_field:\n",
    "                        if idx not in ref_ids:\n",
    "                            ref_ids.append(idx)#[\"int_prot_id\"])\n",
    "                            break\n",
    "    #matches is a tuple of strings used to filter reference sequences in pg_id_df; either \n",
    "    #one entry or genename and then the entry used by the GeneCards page \n",
    "    return ref_ids, matches\n",
    "\n",
    "# test_set = [\"CLEC2D\"]\n",
    "# tmp_errors_fpath = \"tmp/errors.tsv\"\n",
    "# for gene in test_set:\n",
    "\n",
    "#     test_tsv_fpath = run_name+\"/input/{0}.tsv\".format(gene)\n",
    "#     test_tsv = pd.read_csv(test_tsv_fpath,delimiter='\\t')\n",
    "#     test_tsv = test_tsv.set_index(keys=\"int_prot_id\",drop=True)\n",
    "#     display(test_tsv)\n",
    "\n",
    "#     ref_ids, matches = find_ref_seqs(gene,test_tsv,tmp_errors_fpath)\n",
    "    \n",
    "#     ref_tsv = test_tsv.loc[ref_ids,:]\n",
    "#     display(ref_tsv)\n",
    "#     print(ref_ids)\n",
    "\n",
    "#     print(matches)\n",
    "\n",
    "# test_set2 = [\"ATP5G\"]#,\"SADFGH\"]\n",
    "# for name in test_set2:\n",
    "#     pass\n",
    "#     print(download_alias_data(name))\n",
    "#     download_alias_data(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fasta file reading functions: \n",
    "#filter_fasta_infile reads input files and outputs all records corresponding to filtered_ids to a new file\n",
    "#read_fasta_lengths generates a Series object of lengths corresponding to the records in fasta_path \n",
    "\n",
    "def filter_fasta_infile(filtered_ids, infile_path, outfile_path=None,ordered=False):\n",
    "    #If outfile_path is provided, write filtered fasta to outfile_path\n",
    "    \"\"\"Generates new fasta file to outfile_path using the subset of sequences in infile_path\n",
    "    which have ids in filtered_ids\n",
    "    ordered: if true, sequences will be returned/ written in order of filtered_ids\n",
    "             if false, uses sequence order of sequences in infile_path\n",
    "    \"\"\"\n",
    "    def filtered_generator(filtered_ids, infile_path):\n",
    "        fasta_seqs = SeqIO.parse(open(infile_path),'fasta')\n",
    "        for fasta in fasta_seqs:\n",
    "            if fasta.id in filtered_ids:\n",
    "                yield fasta \n",
    "    def ordered_filtered_generator(filtered_ids, infile_path):\n",
    "        for id_ in filtered_ids:\n",
    "            fasta_seqs = SeqIO.parse(open(infile_path),'fasta')\n",
    "            for fasta in fasta_seqs:\n",
    "                if fasta.id == id_:\n",
    "                    yield fasta\n",
    "                    break\n",
    "    if outfile_path:\n",
    "        if ordered:\n",
    "            filtered = ordered_filtered_generator(filtered_ids, infile_path)\n",
    "        else:\n",
    "            filtered = filtered_generator(filtered_ids, infile_path)\n",
    "        SeqIO.write(filtered,outfile_path,\"fasta\")\n",
    "    if ordered:\n",
    "        filtered = ordered_filtered_generator(filtered_ids, infile_path)\n",
    "    else:\n",
    "        filtered = filtered_generator(filtered_ids, infile_path)\n",
    "    filtered_srs = pd.Series(index=filtered_ids)\n",
    "    for fasta in filtered:\n",
    "        filtered_srs[fasta.id] = str(fasta.seq)\n",
    "    return filtered_srs\n",
    "\n",
    "\n",
    "def srs_to_fasta(seq_srs, outfile_path):\n",
    "    #Write records in seq_srs to outfile_path in fasta format \n",
    "    def record_generator(seq_srs):\n",
    "        for idx, seq in seq_srs.iteritems():\n",
    "            record = SeqRecord(Seq(seq,IUPAC.protein),id=idx)\n",
    "            yield record\n",
    "    records = record_generator(seq_srs)\n",
    "    SeqIO.write(records,outfile_path,\"fasta\")\n",
    "\n",
    "def read_fasta_lengths(fasta_path,aligned=False):\n",
    "    #Reads fasta records from fasta_path, returns a Series or non-gap length\n",
    "    #Also returns median and mode lengths for those records\n",
    "    fasta_seqs = SeqIO.parse(open(fasta_path),'fasta')\n",
    "    ids, lengths = [], []\n",
    "    for fasta in fasta_seqs:\n",
    "        ids.append(fasta.id)\n",
    "        if aligned == True:\n",
    "            seq_str = str(fasta.seq)\n",
    "            non_gap_len = len(seq_str) - seq_str.count('-')\n",
    "            lengths.append(non_gap_len)\n",
    "        else:\n",
    "            lengths.append(len(str(fasta.seq)))\n",
    "    id_length_dict = dict(zip(ids,lengths))\n",
    "    med_len = np.median(lengths)\n",
    "    counts = np.bincount(lengths)\n",
    "    mode_len = np.argmax(counts)\n",
    "    return pd.Series(name=\"length\",data=id_length_dict), med_len, mode_len\n",
    "\n",
    "def fasta_to_srs(fasta_path):\n",
    "    fasta_seqs = SeqIO.parse(open(fasta_path),'fasta')\n",
    "    id_seq_map = OrderedDict()\n",
    "    for fasta in fasta_seqs:\n",
    "        record_id = fasta.id\n",
    "        seq = str(fasta.seq)\n",
    "        id_seq_map[record_id] = seq\n",
    "    return pd.Series(name=\"seq\",data=id_seq_map)\n",
    "\n",
    "def align_srs_to_df(align_srs):\n",
    "    #Returns DataFrame object from series of aligned sequences; columns are 1-indexed positions\n",
    "    #Values are characters in alignment, index is ODB sequence IDs\n",
    "    n_seq = len(align_srs)\n",
    "#     display(align_srs)\n",
    "#     display(align_srs.iloc[0])\n",
    "    seq_len = len(align_srs.iloc[0])\n",
    "    align_df = pd.DataFrame(index=align_srs.index,columns=range(seq_len))\n",
    "    for idx, seq in align_srs.iteritems():\n",
    "        align_df.loc[idx,:] = list(seq)\n",
    "    align_df.columns += 1\n",
    "    return align_df\n",
    "\n",
    "def seq_srs_to_align_df(seq_srs,align_in_fpath,align_out_fpath):\n",
    "    \"\"\"Transform seq_srs (pandas Series containing sequence texts) to a DataFrame for which each column\n",
    "    is an alignment position and column. Writes input fasta and output fastas for alignment to align_in_fpath\n",
    "    and align_out_fpath respectively. Also returns average (non-diagonal) identity distances\"\"\"\n",
    "    srs_to_fasta(seq_srs,align_in_fpath)\n",
    "    n, ordered_ids, id_dm, align_srs = construct_id_dm(seq_srs,align_in_fpath,align_out_fpath)\n",
    "    align_df = align_srs_to_df(align_srs)\n",
    "    dist_srs = avg_dist_srs(align_srs.index,id_dm)\n",
    "    return align_df, dist_srs\n",
    "    \n",
    "def align_srs_to_seq_srs(align_srs,outfile_path=None):\n",
    "    #Return new Series (same index) of sequences with gap characters dropped\n",
    "    #If outfile_path is provided, write un-aligned record seqs to new fasta file\n",
    "    seq_srs = pd.Series(index=align_srs.index)\n",
    "    for idx, align_seq in align_srs.iteritems():\n",
    "        seq = align_seq.replace(\"-\",\"\")\n",
    "        seq_srs[idx] = seq\n",
    "    if outfile_path:\n",
    "        srs_to_fasta(seq_srs,outfile_path)\n",
    "    return seq\n",
    "\n",
    "def align_df_to_srs(align_df):\n",
    "    #Returns series of aligned sequences from array of aligned positions\n",
    "    align_srs = pd.Series(index=align_df.index)\n",
    "    for idx,record in align_df.iterrows():\n",
    "#       #seq is a string joining all characters with no delimiter (i.e. the original aligned sequence with gaps)\n",
    "        seq = ''.join(record.values)\n",
    "        align_srs[idx] = seq\n",
    "    return align_srs\n",
    "\n",
    "def truncate_align_df(align_df, record_id):\n",
    "    #Truncates align_df to only the positions corresponding to positions in the sequence of record_id\n",
    "    #Returns truncated_df: new DataFrame of these positions (with reset positions)\n",
    "    # len_adjust_srs: Series with same index as align_df containing counts of non-gap characters dropped \n",
    "    # to get sequences present in truncated_df \n",
    "    record_srs = align_df.loc[record_id]\n",
    "    for index,entry in record_srs.iteritems():\n",
    "        if entry != '-':\n",
    "            trunc_idx, trunc_entry = index, entry   \n",
    "            break\n",
    "    truncated_df = align_df.loc[:,trunc_idx:]\n",
    "    if trunc_idx > 1:\n",
    "        #If some align positions being truncated, iterate over align_df and determine length of sequences\n",
    "        # (i.e. non-gap character count) per record in the truncated fraction of the alignment \n",
    "        pre = align_df.loc[:,:trunc_idx-1]\n",
    "        len_adjust_srs = pd.Series(index=align_df.index)\n",
    "        for index,record in pre.iterrows():\n",
    "            count = 0 \n",
    "            for entry in record:\n",
    "                if entry != '-':\n",
    "                    count += 1\n",
    "            len_adjust_srs[index] = count\n",
    "        #Adjust positions in truncated_df\n",
    "        first_pos = truncated_df.columns[0]\n",
    "        offset = first_pos - 1\n",
    "        truncated_df.columns -= offset\n",
    "    else:\n",
    "        #No truncation necessary to align to shortest known record (length adjustments = 0 for all)\n",
    "        len_adjust_srs = pd.Series(index=align_df.index,data=np.zeros(len(align_df)))\n",
    "    return truncated_df, len_adjust_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ka_distmat(fasta_infile,align_outfile=\"tmp/ka_distmat_align.fasta\",distmat_file=\"tmp/ka_distmat.tsv\"):\n",
    "    \"\"\"REQUIRES: Modified KAlign source code to include distance matrix output, written to tmp/ka_distmat.tsv\n",
    "    Uses KAlign's modified distance metric (Wu-Manber, partial scoring for 3aa patterns with one error \n",
    "    tolerated), outputs to tsv and reads and stores as an ndarray (n x n) with n = number of sequences in fasta_infile\n",
    "    \n",
    "    Also return a list of the ODB ids of sequences (in order) corresponding to the distmat/ alignment order\n",
    "    \"\"\"\n",
    "    proc = subprocess.run(args=[\"kalign\",'-i',fasta_infile,\"-o\",align_outfile,\"-f\",\"fasta\"])\n",
    "    distmat_flines = open(distmat_file).readlines()\n",
    "    n = len(distmat_flines)\n",
    "    distmat = np.ndarray((n,n))\n",
    "    \n",
    "    for i,line in enumerate(distmat_flines):\n",
    "        as_list = line.split()\n",
    "        line_arr = np.array(as_list).astype(np.float)\n",
    "        distmat[i] = line_arr\n",
    "    ordered_ids = []\n",
    "    align_seqs = SeqIO.parse(open(align_outfile),'fasta')\n",
    "    for record in align_seqs:\n",
    "        ordered_ids.append(record.id)\n",
    "    return n, ordered_ids, distmat, align_outfile\n",
    "def construct_id_dm(seq_df,seq_fpath,align_outpath=\"tmp/iddm_align.fasta\",ordered=False):\n",
    "    from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "    from Bio import AlignIO\n",
    "    #Filter records in seq_fpath to new fasta only containing records in seq_df.index\n",
    "    filtered_outpath = \"tmp/iddm.fasta\"\n",
    "    filter_fasta_infile(seq_df.index,seq_fpath,outfile_path=filtered_outpath,ordered=ordered)\n",
    "    #KAlign sequences in filtered_outpath, write to align_outpath\n",
    "    n, ordered_ids, ka_dm, align_outfile = load_ka_distmat(filtered_outpath,align_outfile=align_outpath)\n",
    "    align_srs = fasta_to_srs(align_outpath)\n",
    "    aln = AlignIO.read(open(align_outpath), 'fasta')\n",
    "    calculator = DistanceCalculator('identity')\n",
    "    id_dm_obj = calculator.get_distance(aln)\n",
    "    #Convert AlignIO object to np.ndarray\n",
    "    for i,r in enumerate(id_dm_obj):\n",
    "        if i == 0:\n",
    "            id_dm = np.array(r)\n",
    "        else:\n",
    "            id_dm = np.vstack((id_dm,r))\n",
    "    return n, ordered_ids, id_dm, align_srs\n",
    "def avg_dist_srs(index,distmat):\n",
    "    #index is a pandas Index object with entries corresponding to the distmat (i.e. lengths should be equal)\n",
    "    #Calculate mean of non-self record distances (pairwise distance with self is 0, so sum functions as intended)\n",
    "    n = len(distmat)\n",
    "    avg_dists = np.sum(distmat, axis=1)/(n-1)\n",
    "    dist_srs = pd.Series(data=avg_dists,index=index,name=\"dist\")\n",
    "    return dist_srs\n",
    "\n",
    "def load_dist_length_data(ref_ids,ref_fasta_path,ref_tsv,aligned=False):\n",
    "    #Returns a dataframe based off of ODB tsv files but with sequence length and average KAlign distance included\n",
    "    metrics = {}\n",
    "    n, ordered_ids, distmat, align_outfile = load_ka_distmat(ref_fasta_path)\n",
    "    metrics[\"n\"] = n\n",
    "    ref_align_series = fasta_to_srs(align_outfile)\n",
    "    lengths, med_len, mode_len = read_fasta_lengths(ref_fasta_path,aligned)\n",
    "    metrics[\"median_len\"] = med_len\n",
    "    metrics[\"mode_len\"] = mode_len\n",
    "    #Average non-diagonal (which is always 0) distmat entries\n",
    "    ref_dist_srs = avg_dist_srs(ordered_ids, distmat)\n",
    "    #Incorporate average dists into ref_df\n",
    "    ref_df = pd.DataFrame(index=ordered_ids,data={\"dist\":ref_dist_srs,\"length\":lengths, \\\n",
    "                                                             \"align\":ref_align_series})\n",
    "    ref_df = ref_df.merge(ref_tsv,how=\"inner\",left_index=True,right_index=True)\n",
    "    if \"level_taxid\" in ref_df:\n",
    "        ref_df.drop(columns=\"level_taxid\",inplace=True)\n",
    "    reordered_cols = [\"dist\",\"length\",\"pub_og_id\",\"og_name\",\"organism_taxid\",\"organism_name\",\"pub_gene_id\",\"description\",\"align\"]\n",
    "    ref_df = ref_df[reordered_cols]\n",
    "    return ref_df, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper_matches = [\"CALM1\",\"ATP5G\"]\n",
    "# upper_matches = [match+\"$|\"+match+\"[^\\w]\" for match in upper_matches]\n",
    "# target_strs = [\"CALM1;CALM2;CALM3\", \"CALM1\",\"CALM2;CALM1\", \"ATP5G\", \"ATP5G;SLAD\",\"SADKFJG;ATP5G\", \"CALM12\"]\n",
    "# pat = \"|\".join(upper_matches)\n",
    "# print(pat)\n",
    "# for target in target_strs:\n",
    "#     print(re.search(pat, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_id_match_df(unfiltered_df,matches):\n",
    "    \"\"\"From an unfiltered_df of reference sequences, returns a DataFrame of all entries which have pub_gene_id\n",
    "    matching genename. If any species has more than one such sequence, only one entry will be kept, selected\n",
    "    by the lowest average distance to the entire reference set. \n",
    "    \"\"\"\n",
    "#     display(unfiltered_df)\n",
    "    upper_matches = [match.upper() for match in matches]\n",
    "    upper_matches = [match+\"$|\"+match+\"[^\\w]\" for match in upper_matches]\n",
    "#     pg_id_df = unfiltered_df.loc[unfiltered_df[\"pub_gene_id\"].str.upper().isin(upper_matches)]\n",
    "    pat = \"|\".join(upper_matches)\n",
    "    pg_id_df = unfiltered_df.loc[unfiltered_df[\"pub_gene_id\"].str.upper().str.contains(pat)]\n",
    "    #Filtering for any species with more than one sequence\n",
    "    final_df = pd.DataFrame(columns=pg_id_df.columns)\n",
    "    for unique_tax in pg_id_df[\"organism_taxid\"].unique():\n",
    "        spec_df = pg_id_df.loc[pg_id_df[\"organism_taxid\"] == unique_tax]\n",
    "        if len(spec_df) > 1:\n",
    "            spec_df_index = spec_df.index\n",
    "            min_dist_idx = spec_df[\"dist\"].values.argmin()\n",
    "            min_dist_row = spec_df.iloc[min_dist_idx,:]\n",
    "            final_df = final_df.append(min_dist_row)\n",
    "            #Remove all entries for this tax_id and append only the minimum distance row\n",
    "#             pg_id_df.drop(spec_df.index,inplace=True)\n",
    "#             pg_id_df = pg_id_df.append(min_dist_row)\n",
    "        else:\n",
    "            final_df = final_df.append(spec_df)\n",
    "    return final_df\n",
    "\n",
    "def final_input_df(pg_id_df,unfiltered_df):\n",
    "    #Determine sets of values for NCBI taxid/ ODB description for which records exist in pg_id_df\n",
    "    #i.e. ODB input records with pub_gene_id had matches to genename or its aliases\n",
    "    #Final DataFrame will have extra column \"\" noting the type of annotation used to determine record validity\n",
    "    pg_id_tax_set = pg_id_df[\"organism_taxid\"].unique()\n",
    "    pg_id_desc_set = set([format_odb_field(desc) for desc in pg_id_df[\"description\"].unique()])\n",
    "    filtered_df = pd.DataFrame(columns=pg_id_df.columns.append(pd.Index([\"record_type\"])))\n",
    "#     filtered_df = pd.DataFrame(columns=pd.Index([\"record_type\"]).append(pg_id_df.columns))\n",
    "    threshold_dist = pg_id_df[\"dist\"].max()\n",
    "    for ref_tax in unfiltered_df[\"organism_taxid\"].unique():\n",
    "        if ref_tax in pg_id_tax_set:\n",
    "            #Check lengths against rest of pg_id_df\n",
    "            pg_row = pg_id_df.loc[pg_id_df[\"organism_taxid\"] == ref_tax]\n",
    "            pg_row[\"record_type\"] = \"pubgene_id match\"\n",
    "            filtered_df = filtered_df.append(pg_row)\n",
    "            continue \n",
    "        else:\n",
    "            #Check if any of entries have description matching Gene annotated sequences\n",
    "            spec_df = unfiltered_df[unfiltered_df[\"organism_taxid\"] == ref_tax]\n",
    "            desc_match_srs = spec_df[\"description\"].apply(format_odb_field).isin(pg_id_desc_set)\n",
    "            desc_match_df = spec_df.loc[desc_match_srs,:]\n",
    "            #If records for this taxid have matches with the description values (pg_id_desc_set), \n",
    "            #Choose the min distance entry from desc_match_df\n",
    "            #Else choose the min distance entry for this tax_id (from spec_df)\n",
    "            if desc_match_df.empty:\n",
    "                min_dist_idx = spec_df[\"dist\"].values.argmin()\n",
    "                record_type = \"No ODB match\"\n",
    "            else:\n",
    "                min_dist_idx = desc_match_df[\"dist\"].values.argmin()\n",
    "                record_type = \"ODB description match\"\n",
    "            min_dist_row = spec_df.iloc[min_dist_idx,:]\n",
    "            min_dist_row[\"record_type\"] = record_type\n",
    "            if min_dist_row[\"dist\"] < threshold_dist:\n",
    "                filtered_df = filtered_df.append(min_dist_row)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ref_seqs4(gene_name,matches,ref_fasta_path,ref_df,seq_qc_fpath,known_spec_list=[\"10090_0\",\"9606_0\",\"43179_0\"]):\n",
    "    ref_ids = list(ref_df.index)\n",
    "#     ksr_tsv_df = ref_tsv.loc[ref_tsv[\"organism_taxid\"].isin(known_spec_list)]\n",
    "    ksr_ref_df = ref_df.loc[ref_df[\"organism_taxid\"].isin(known_spec_list)]\n",
    "    #Create new tmp fasta file with known species annotated records only\n",
    "    ks_refseqs_fpath = \"tmp/ks_refseqs.fasta\"\n",
    "    known_spec_records = filter_fasta_infile(ksr_ref_df.index,ref_fasta_path,outfile_path=ks_refseqs_fpath)\n",
    "    \n",
    "    #Search ksr_full_df for pub_gene_id field matches to main aliases (matches)\n",
    "    upper_matches = [\"{0}$|{0}[;]\".format(match.upper()) for match in matches]\n",
    "    matches_pat = \"|\".join(upper_matches)\n",
    "    ksr_pgid_df = ksr_ref_df.loc[ksr_ref_df[\"pub_gene_id\"].str.upper().str.contains(matches_pat)]\n",
    "    final_ksr_df = select_known_species_records(ksr_pgid_df,ksr_ref_df,ks_refseqs_fpath)\n",
    "    #Quality checking of final_ksr_df:\n",
    "    final_ksr_df_QC(gene_name,matches,seq_qc_fpath,final_ksr_df,known_spec_list)\n",
    "    ref_pgid_df = ref_df.loc[ref_df[\"pub_gene_id\"].str.upper().str.contains(matches_pat)]\n",
    "    final_df = select_species_records(ref_pgid_df,ref_df,final_ksr_df,ref_fasta_path)\n",
    "    length_filter = True\n",
    "    if length_filter:\n",
    "        #Remove records whose length differs by more than 10% from the median (but keep representative seqs for \n",
    "        #human, mouse, GS)\n",
    "        med_len = final_df[\"length\"].median()\n",
    "        len_filtered = final_df.loc[(np.abs((final_df[\"length\"]-med_len)/med_len) < 0.1) | (final_df[\"organism_taxid\"].isin(known_spec_list)),:]\n",
    "        final_df = len_filtered\n",
    "    return final_df\n",
    "\n",
    "def select_known_species_records(ksr_pgid_df,ksr_ref_df,ks_refseqs_fpath):\n",
    "    \"\"\"Return a dataframe of at most one record per species in KS_taxids, selecting first if there is only \n",
    "    one pubgene_id match record for that species and otherwise selecting the record with maximum identity\n",
    "    with other single pgid matched records, preferable from pgid_df but from ksr_ref_df if no pgid match exists\n",
    "    for that species\"\"\"\n",
    "    TEST_ID = \"43179_0\"\n",
    "    KS_TAXIDS = [\"10090_0\",\"43179_0\",\"9606_0\"]\n",
    "    ksr_taxid_uniques = ksr_ref_df[\"organism_taxid\"].unique()\n",
    "    pgid_taxid_uniques = ksr_pgid_df[\"organism_taxid\"].unique()\n",
    "    \n",
    "    #Case Handling: Only one species in ksr_pgid\n",
    "    if len(ksr_taxid_uniques) == 1 and TEST_ID in ksr_taxid_uniques:\n",
    "        raise SequenceDataError(3,\"No Human or Mouse reference sequences\")\n",
    "            \n",
    "    #Case Handling - if ksr_pgid_df is not composed of one sequence each for human, mouse, 13LGS\n",
    "    if len(ksr_pgid_df) > 3 or len(pgid_taxid_uniques) <3:\n",
    "        single_match_pgid_records = pd.DataFrame(columns=ksr_pgid_df.columns)\n",
    "        for ks_id in KS_TAXIDS:\n",
    "            ks_pgid_df = ksr_pgid_df.loc[ksr_pgid_df[\"organism_taxid\"]==ks_id,:]\n",
    "            if len(ks_pgid_df) == 1:\n",
    "                single_match_pgid_records = single_match_pgid_records.append(ks_pgid_df)\n",
    "                \n",
    "        if single_match_pgid_records.empty:\n",
    "            #Case handling if no single_match_records (ie CALM1): \n",
    "            #Allow manual input selection from either ksr_pgid_df or ksr_ref_df, raise SequenceDataError if both empty\n",
    "            if not ksr_pgid_df.empty: \n",
    "                print(\"pubgeneID matched records\")\n",
    "                display(ksr_pgid_df)\n",
    "                selection_df = ksr_pgid_df\n",
    "            elif not ksr_ref_df.empty:\n",
    "                print(\"GeneCards alias matched records\")\n",
    "                display(ksr_ref_df)\n",
    "                selection_df = ksr_ref_df\n",
    "            else:\n",
    "                raise SequenceDataError(2,\"No GeneCards alias matched sequence records for human/mouse/GS\")\n",
    "            try: \n",
    "                input_idx = input(\"Enter 0-indexed position of representative sequence for analysis\")\n",
    "                int_idx = int(input_idx)\n",
    "                selection_row = selection_df.iloc[int_idx,:]\n",
    "                \n",
    "            except (IndexError, ValueError) as e:\n",
    "                print(\"Bad Input\")\n",
    "                while (not re.search(\"^\\d+$\",input_idx)) or (int(input_idx)>=len(selection_df) or int(input_idx)<0):\n",
    "                    input_idx = input(\"Enter a number between 0 and {0}\".format(len(selection_df)-1))\n",
    "                int_idx = int(input_idx)\n",
    "                selection_row = selection_df.iloc[int_idx,:]\n",
    "            single_match_pgid_records = single_match_pgid_records.append(selection_row)\n",
    "\n",
    "        final_ksr_df = pd.DataFrame(columns=single_match_pgid_records.columns)\n",
    "        sm_record_ids = single_match_pgid_records.index                   \n",
    "            \n",
    "        for ks_id in KS_TAXIDS:\n",
    "            if ks_id not in single_match_pgid_records[\"organism_taxid\"].unique():\n",
    "            #For known_species taxids with 0 or 2+ pgid records: first check pgid matches (2+ pgid), then ref seqs (0 pgid)\n",
    "                if ks_id in pgid_taxid_uniques:\n",
    "                    #2+ pgid records: Construct id_dm of pgid matched records; select best ks_id \n",
    "                    #based on max identity with single_match_records\n",
    "                    n, ordered_ids, id_dm, align_srs = construct_id_dm(ksr_pgid_df,ks_refseqs_fpath)\n",
    "                elif ks_id in ks_id in ksr_taxid_uniques:\n",
    "                    #0 pgid records; construct id_dm from ksr_ref_df records, select max identity record\n",
    "                    n, ordered_ids, id_dm, align_srs = construct_id_dm(ksr_ref_df,ks_refseqs_fpath)\n",
    "                else:\n",
    "                    continue\n",
    "                #Maximum identity = minimum id_dm value based on AlignIO implementation\n",
    "                md_row, min_dist = min_dist_spec_record(ks_id,id_dm,ordered_ids,sm_record_ids,ksr_ref_df)\n",
    "                final_ksr_df = final_ksr_df.append(md_row)\n",
    "            else:\n",
    "                sm_row = single_match_pgid_records.loc[single_match_pgid_records[\"organism_taxid\"]==ks_id,:]\n",
    "                final_ksr_df = final_ksr_df.append(sm_row)\n",
    "        return final_ksr_df\n",
    "                \n",
    "    else:\n",
    "        #Sort ksr_pgid_df to order of taxids in KS_TAXIDS\n",
    "        final_ksr_df = pd.DataFrame(columns=ksr_pgid_df.columns)\n",
    "        for tax_id in KS_TAXIDS:\n",
    "            row = ksr_pgid_df.loc[ksr_pgid_df[\"organism_taxid\"]==tax_id,:]\n",
    "            final_ksr_df = final_ksr_df.append(row)\n",
    "        return final_ksr_df\n",
    "    \n",
    "def select_species_records(ref_pgid_df,ref_df,final_ksr_df,refseqs_fpath):\n",
    "    TEST_ID = \"43179_0\"\n",
    "    KS_TAXIDS = [\"10090_0\",\"43179_0\",\"9606_0\"]\n",
    "    pgid_taxids = [tax_id for tax_id in ref_pgid_df[\"organism_taxid\"].unique() if tax_id not in KS_TAXIDS]\n",
    "    ref_taxids = [tax_id for tax_id in ref_df[\"organism_taxid\"].unique() if tax_id not in KS_TAXIDS]\n",
    "    \n",
    "    #Distance calculations for final set of known species records - check internal identity values\n",
    "    #Set identity threshold - other species sequences above this value will not be included\n",
    "    ksr_dm_fpath = \"tmp/ksr_dm_ka.fasta\"\n",
    "    n, ksr_ordered_ids, ksr_id_dm, ksr_align_srs = construct_id_dm(final_ksr_df,refseqs_fpath,ksr_dm_fpath,ordered=True)\n",
    "    non_diagonal_avg = ksr_id_dm.sum(axis=0)/(n-1)\n",
    "    max_dist_idx = non_diagonal_avg.argmax()\n",
    "    max_dist_id = ksr_ordered_ids[max_dist_idx]\n",
    "    max_dist = non_diagonal_avg[max_dist_idx]\n",
    "    identity_threshold = np.mean(non_diagonal_avg)*1.5\n",
    "    \n",
    "    final_df = final_ksr_df.copy()\n",
    "    unfiltered_df = final_ksr_df.copy()\n",
    "    for tax_id in ref_taxids:\n",
    "        try:\n",
    "            tax_df = ref_df.loc[ref_df[\"organism_taxid\"]==tax_id]\n",
    "            tax_records = tax_df.index\n",
    "            #tax_dm_filtered_ids: list of record ids in final_ksr_df followed by all records corresponding to tax_id\n",
    "            tax_dm_filtered_ids = list(final_ksr_df.index)\n",
    "            tax_dm_filtered_ids.extend(tax_records) \n",
    "            tax_dm_df = ref_df.loc[tax_dm_filtered_ids,:]\n",
    "#             tax_dm_df.drop_duplicates(inplace=True)\n",
    "            tax_dm_df = tax_dm_df.loc[~tax_dm_df.index.duplicated(keep='first')]\n",
    "            tax_dm_fpath = \"tmp/{0}_dm.fasta\".format(tax_id)\n",
    "            n, tax_ordered_ids, tax_id_dm, tax_align_srs = construct_id_dm(tax_dm_df,refseqs_fpath,tax_dm_fpath,ordered=True)\n",
    "            md_row, min_dist = min_dist_spec_record(tax_id,tax_id_dm,tax_ordered_ids,final_ksr_df.index,tax_dm_df)\n",
    "            if min_dist <= identity_threshold:\n",
    "                final_df = final_df.append(md_row)\n",
    "        except ValueError as e:\n",
    "            #Debugging edge case for OrthoDB data error with duplicate entries (Irf2bp2)\n",
    "            print(e)\n",
    "            display(tax_dm_df)\n",
    "            raise SequenceDataError(5,\"Duplicate Sequence Entry\")\n",
    "    return final_df    \n",
    "        \n",
    "def final_ksr_df_QC(gene_name,matches,seq_qc_fpath,final_ksr_df,ks_taxids):\n",
    "    #Writes warnings about compiled final known species records (ie after select_known_species_records)\n",
    "    #to specified file path\n",
    "    if len(final_ksr_df) < len(ks_taxids):\n",
    "        for tax_id in ks_taxids:\n",
    "            if tax_id not in final_ksr_df[\"organism_taxid\"].unique():\n",
    "                message_txt = \"No reference sequence for tax_id: {0}\".format(tax_id)\n",
    "                write_ref_seq_QC(seq_qc_fpath,gene_name,message_txt)\n",
    "    length_srs = final_ksr_df[\"length\"]\n",
    "    median_len = length_srs.median()\n",
    "    for record_id in final_ksr_df.index:\n",
    "        id_len = length_srs[record_id]\n",
    "        if (np.abs(id_len-median_len)/median_len) >= 0.1:\n",
    "            message_txt = \"Record_id {0} has length {1} which is greater than 10% different from the median ({2})\".format(record_id,id_len,median_len)\n",
    "            write_ref_seq_QC(seq_qc_fpath,gene_name,message_txt)\n",
    "    upper_matches = [match.upper() for match in matches]\n",
    "    upper_matches = [match+\"$|\"+match+\"[;]\" for match in upper_matches]\n",
    "    pat = \"|\".join(upper_matches)\n",
    "#     final_pgid_df = final_ksr_df.loc[final_ksr_df[\"pub_gene_id\"].str.upper().str.contains(pat)]\n",
    "    for record_id,pgid in final_ksr_df[\"pub_gene_id\"].iteritems():\n",
    "        if not re.search(pat,pgid.upper()):\n",
    "            message_txt = \"Record_id {0} has pub_gene_id {1} which doesn't match gene_name ({2})\".format(record_id,pgid,gene_name)\n",
    "            write_ref_seq_QC(seq_qc_fpath,gene_name,message_txt)\n",
    "def write_ref_seq_QC(seq_qc_fpath,gene_name,message):\n",
    "    \"\"\"Writes warning messages to seq_qc_fpath and prints (will not write duplicate entries)\"\"\"\n",
    "    if not os.path.exists(seq_qc_fpath):\n",
    "        seq_qc_f = open(seq_qc_fpath,'wt')\n",
    "        seq_qc_f.write(\"gene\\tmessage\\n\")\n",
    "    else:\n",
    "        seq_qc_f = open(seq_qc_fpath,'at')\n",
    "        seq_qc_df = pd.read_csv(seq_qc_fpath,delimiter='\\t')\n",
    "        if gene_name in seq_qc_df[\"gene\"].unique():\n",
    "            gene_df = seq_qc_df[seq_qc_df[\"gene\"]==gene_name]\n",
    "            if message not in gene_df[\"message\"].unique():\n",
    "                fline = \"{0}\\t{1}\\n\".format(gene_name,message)\n",
    "                seq_qc_f.write(fline)\n",
    "            else:\n",
    "                stored_message = seq_qc_df[seq_qc_df[\"gene\"]==gene_name][\"message\"].iloc[0]\n",
    "                print(\"Cached QC Warning:\")\n",
    "                message = stored_message\n",
    "        else:\n",
    "            fline = \"{0}\\t{1}\\n\".format(gene_name,message)\n",
    "            seq_qc_f.write(fline)\n",
    "    print(\"{0}: {1}\".format(gene_name,message))\n",
    "\n",
    "    \n",
    "def min_dist_spec_record(spec_taxid,distmat,dm_record_ids,accepted_record_ids, ref_df):\n",
    "    \"\"\"Given a species taxid (spec_taxid), an np.ndarray distance matrix (distmat), a list of record_ids\n",
    "    corresponding to the rows in distmat (dm_record_ids),a list of accepted record ids (accepted_record_ids)\n",
    "    against which record distances will be averaged, and a DataFrame of sequences (ref_df):\n",
    "    Calculates the average distance of every record containing spec_taxid against accepted records, then\n",
    "    returns the row from ref_df corresponding to the record with lowest average distance\"\"\" \n",
    "    spec_records = [(i,id_) for i,id_ in enumerate(dm_record_ids) if re.search(spec_taxid,id_)]\n",
    "    spec_dm_idxs = [t[0] for t in spec_records] \n",
    "    accepted_records = [(i,id_) for i,id_ in enumerate(dm_record_ids) if id_ in accepted_record_ids]\n",
    "    accepted_dm_idxs = [t[0] for t in accepted_records]\n",
    "\n",
    "    spec_dm = distmat[:,spec_dm_idxs]\n",
    "    sub_dm = spec_dm[accepted_dm_idxs,:]\n",
    "    if len(sub_dm) > 1:\n",
    "        avg_dist = sub_dm.mean(axis=0)\n",
    "    else:\n",
    "        avg_dist = sub_dm[0]\n",
    "    min_idx = np.argmin(avg_dist)\n",
    "    min_dist_id = spec_records[min_idx][1]\n",
    "    min_dist = avg_dist[min_idx]\n",
    "    md_row = ref_df.loc[min_dist_id,:]\n",
    "    return md_row, min_dist\n",
    "\n",
    "\n",
    "#===================== \n",
    "test_set_1 = [\"CALM1\",\"CALCOCO2\"]\n",
    "# gene_set_1 = gene_list\n",
    "# gene_set_1 = [\"VMP1\",\"CALM1\"]\n",
    "# errors_fpath = \"tmp/errors.tsv\"\n",
    "# for gene_name in test_set_1[:]:\n",
    "#     fasta_path = run_name+\"/input/\"+gene_name+\".fasta\"\n",
    "#     tsv_path = run_name+\"/input/\"+gene_name+\".tsv\"\n",
    "#     ref_fasta_path = \"tmp/ref_seqs.fasta\"\n",
    "    \n",
    "#     try: \n",
    "#         tsv_df = pd.read_csv(tsv_path,delimiter='\\t')\n",
    "#         unfiltered_n = len(tsv_df[\"organism_taxid\"].unique())\n",
    "#         tsv_df = tsv_df.set_index(keys=\"int_prot_id\",drop=True)#drop=False)\n",
    "#         ref_ids, matches = find_ref_seqs(gene_name,tsv_df,errors_fpath)\n",
    "#         if len(ref_ids) == 0:\n",
    "#             write_errors(errors_fpath,gene_name,1)\n",
    "#         elif test_species not in tsv_df[\"organism_name\"].values:\n",
    "#             write_errors(errors_fpath,gene_name,2)\n",
    "#         ref_tsv = tsv_df.loc[ref_ids,:]\n",
    "#         filtered_seq_srs = filter_fasta_infile(ref_ids,fasta_path,outfile_path=ref_fasta_path)\n",
    "#         ref_seq_df = pd.DataFrame(filtered_seq_srs,columns=[\"seq\"])\n",
    "#         ref_seq_df[\"length\"] = [len(seq) for seq in ref_seq_df[\"seq\"]]\n",
    "#         ref_df = ref_tsv.join(ref_seq_df,how=\"inner\")\n",
    "#         if test_species not in ref_tsv[\"organism_name\"].values:\n",
    "#             raise SequenceDataError(4,\"Test Species has no reference sequence in input (but a record is present in unfiltered ODB query)\")\n",
    "#         final_records_df = filter_ref_seqs4(gene_name,matches,ref_fasta_path, ref_df,seq_qc_fpath)\n",
    "# #         final_align_df = seq_srs_to_align_df(final_records_df[\"seq\"],)\n",
    "#     except Exception as e:\n",
    "#         print(\"==={0}===\".format(gene_name))\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(id_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref Sequence Testing \n",
    "gene_set_1 = [\"CALM1\",\"ATP5G1\"]\n",
    "\n",
    "def process_input(gene_name, run_name, test_species, errors_fpath, seq_qc_fpath,drop_spec_list=None):\n",
    "    #Generates final record and final alignment dataframes from raw input files. \n",
    "    #If errors arise (see write_errors), updates errors_fpath accordingly\n",
    "\n",
    "    input_fasta_fpath = \"{0}/input/{1}.fasta\".format(run_name,gene_name)\n",
    "    input_tsv_fpath = \"{0}/input/{1}.tsv\".format(run_name,gene_name)\n",
    "    gene_output_dir = \"{0}/output/{1}\".format(run_name,gene_name)\n",
    "    create_directory(gene_output_dir)\n",
    "    MSA_input_fasta = \"{0}/output/{1}/{1}.fasta\".format(run_name,gene_name)\n",
    "    MSA_output_fasta = \"{0}/output/{1}/{1}_MSA.fasta\".format(run_name,gene_name)\n",
    "    ref_fasta_path = \"tmp/ref_seqs.fasta\"\n",
    "    try: \n",
    "        tsv_df = pd.read_csv(input_tsv_fpath,delimiter='\\t')\n",
    "#         unfiltered_n = len(tsv_df[\"organism_taxid\"].unique())\n",
    "        tsv_df = tsv_df.set_index(keys=\"int_prot_id\",drop=True)#drop=False)\n",
    "    except (EmptyDataError, FileNotFoundError) as e:\n",
    "        raise OrthoDBQueryError(0,\"No OrthoDB results for query\")\n",
    "    if drop_spec_list:\n",
    "        tsv_df = tsv_df.loc[~tsv_df[\"organism_taxid\"].isin(drop_spec_list),:] \n",
    "    ref_ids, matches = find_ref_seqs(gene_name,tsv_df,errors_fpath)\n",
    "    if len(ref_ids) == 0:\n",
    "        raise SequenceDataError(0,\"No reference sequences could be found\")\n",
    "    elif test_species not in tsv_df[\"organism_name\"].values:\n",
    "        raise SequenceDataError(1,\"Test Species has no sequence in input\")\n",
    "    ref_tsv = tsv_df.loc[ref_ids,:]\n",
    "    \n",
    "    filtered_seq_srs = filter_fasta_infile(ref_ids,input_fasta_fpath,outfile_path=ref_fasta_path)\n",
    "    ref_seq_df = pd.DataFrame(filtered_seq_srs,columns=[\"seq\"])\n",
    "    ref_seq_df[\"length\"] = [len(seq) for seq in ref_seq_df[\"seq\"]]\n",
    "    ref_df = ref_tsv.join(ref_seq_df,how=\"inner\")\n",
    "    \n",
    "    if test_species not in ref_tsv[\"organism_name\"].values:\n",
    "        raise SequenceDataError(4,\"Test Species has no reference sequence in input (but a record is present in unfiltered ODB query)\")\n",
    "    final_records_df = filter_ref_seqs4(gene_name,matches,ref_fasta_path, ref_df,seq_qc_fpath)\n",
    "    final_align_df, dist_srs = seq_srs_to_align_df(final_records_df[\"seq\"],MSA_input_fasta,MSA_output_fasta)\n",
    "    final_records_df.loc[:,\"dist\"] = dist_srs\n",
    "\n",
    "#     print(\"Final Records DataFrame\")\n",
    "#     display(final_records_df)\n",
    "#     print(\"Final Alignment DataFrame\")\n",
    "#     display(final_align_df)\n",
    "    return final_records_df, final_align_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_uniques(align_df, sub_freq_threshold, test_species_idx,display_uniques):\n",
    "    #align\n",
    "    uniques = pd.DataFrame(index=align_df.index)\n",
    "    for pos in align_df:\n",
    "        col = align_df[pos]\n",
    "        sub_counts = col.value_counts()\n",
    "        c_counts = sub_counts.value_counts()\n",
    "        for index,value in sub_counts.iteritems():\n",
    "    #         if(value == 1):# and c_counts.loc[value] == 1:\n",
    "            if value <= sub_freq_threshold:\n",
    "                if col[test_species_idx] == index and index != 'X':\n",
    "                    uniques.loc[:,pos] = col\n",
    "                    break\n",
    "    if display_uniques:\n",
    "        print(\"Threshold Number of Sequences: \"+str(int(sub_freq_threshold)))#/len(ordered)))\n",
    "        print(\"Species specific residues for \"+test_species)\n",
    "        display(uniques)\n",
    "    return uniques\n",
    "\n",
    "# uniques = find_uniques(align_df,sub_freq_threshold, display_uniques)\n",
    "# display(align_df)\n",
    "# display(uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def force_positions(align_df, test_species, positions):\n",
    "# def force_insertion(align_df,species,pos,sub):\n",
    "def gap_ratio(col):\n",
    "    return sum([c == '-' for c in col])/len(col)\n",
    "\n",
    "def sub_ratio(col,sub):\n",
    "    return sum([c == sub for c in col])/len(col)\n",
    "\n",
    "def species_gaps_dict(align_df,gap_char='-'):\n",
    "    gaps_dict = OrderedDict()\n",
    "    unique_gaps = OrderedDict()\n",
    "    unique_subs = OrderedDict()\n",
    "    align_nd = align_df.values\n",
    "    for j,spec in enumerate(align_df.index):\n",
    "        gaps_dict[spec] = []\n",
    "        unique_gaps[spec] = []\n",
    "        unique_subs[spec] = []\n",
    "        spec_row = align_df.loc[spec,:].values\n",
    "#         row = align_nd[j]\n",
    "        for i,entry in enumerate(spec_row):\n",
    "#             outgroup_col_ = align_df.iloc[:,i].copy()\n",
    "            outgroup_col_ = align_nd.T[i].copy()\n",
    "#             outgroup_col_.drop(spec,inplace=True)\n",
    "            outgroup_col_ = np.delete(outgroup_col_,obj=j)\n",
    "            ratio = gap_ratio(outgroup_col_)\n",
    "            if entry == gap_char:\n",
    "                gaps_dict[spec].append(i+1)\n",
    "                #Check if remainder of positions have gap; if none do, add to unique gaps.\n",
    "                if ratio <= 0.1:\n",
    "                    unique_gaps[spec].append(i+1)\n",
    "            else:\n",
    "                if ratio >= 0.9:\n",
    "                    unique_subs[spec].append(i+1)\n",
    "                     \n",
    "    return gaps_dict, unique_gaps, unique_subs\n",
    "\n",
    "def seq_to_align_pos(seq_pos,species,gap_dict):\n",
    "    spec_gaps = gap_dict[species]\n",
    "    for gap in spec_gaps:\n",
    "        if gap <= seq_pos:\n",
    "            seq_pos += 1 \n",
    "    return seq_pos\n",
    "\n",
    "def outgroup_seq_pos(gaps,test_pos,test_species,out_species):\n",
    "    test_gaps = gaps[test_species]\n",
    "    out_gaps = gaps[out_species]\n",
    "    out_pos = test_pos\n",
    "    for test_gap in test_gaps:\n",
    "        if test_gap <= out_pos and test_gap not in out_gaps:\n",
    "            out_pos += 1\n",
    "    for out_gap in out_gaps:\n",
    "        if out_gap <= out_pos and out_gap not in test_gaps:\n",
    "            out_pos -= 1\n",
    "#             print(\"hurray\")\n",
    "    return out_pos\n",
    "            \n",
    "\n",
    "def force_noshift(align_df,test_species,subs):\n",
    "    test_row = align_df.loc[test_species,:]\n",
    "    for pos in subs:\n",
    "        sub = subs[pos]\n",
    "        if test_row.loc[pos] != sub:\n",
    "            test_row.loc[pos] = sub\n",
    "def convert_sub_str(sub_str):\n",
    "    #Converts a substitution string (i.e. P39T) into a tuple of (position,outgroup variant,test variant) \n",
    "    #for example 'P39T' -> (39,'P','T')\n",
    "    try:\n",
    "        groups = re.search(\"([A-Z])(\\d+)([A-Z])\",sub_str).groups()\n",
    "        out,pos,test = groups[0],int(groups[1]),groups[2]\n",
    "        return (pos,out,test)\n",
    "    except AttributeError as e:\n",
    "#         raise UserWarning(\"oops\")\n",
    "        print(sub_str+\" did not match expected pattern i.e. P39T, A79V\")\n",
    "        print(\"Will not attempt to realign for this input string\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "def force_with_shifts(align_df,test_species,sub_str,gap_dict,unique_gaps):\n",
    "#subs is a dictionary from positions to tuples of (outgroup substitution, test variant)\n",
    "    sub = convert_sub_str(sub_str)\n",
    "    if sub:\n",
    "        seq_pos,out,test = sub[0],sub[1],sub[2]\n",
    "        #Check test is at seq_pos\n",
    "        align_pos = seq_to_align_pos(seq_pos,test_species,gap_dict)\n",
    "        test_variant = align_df.loc[test_species,align_pos]\n",
    "        if test_variant != test:\n",
    "            print(\"Input string: \"+sub_str)\n",
    "            print(\"Could not find specified substitution at specified position. Alignment will not be changed Continuing...\")\n",
    "            pass\n",
    "        else:\n",
    "            #Idea: generate outgroup seq pos for each outgroup species individually. Check consensus of position, use mode to select for predicted position. Check substitution at that position. Threshold. \n",
    "            outgroup = align_df.index.copy().drop(test_species)\n",
    "            for out_species in outgroup:\n",
    "                out_seq_pos = outgroup_seq_pos(gap_dict,seq_pos,test_species,out_species)\n",
    "                out_align_pos = seq_to_align_pos(out_seq_pos,out_species,gap_dict)\n",
    "    else:    \n",
    "        pass\n",
    "        \n",
    "def align_pos_to_native_pos(align_df, test_species, align_pos):\n",
    "    pre_pos = align_df.loc[test_species,:align_pos-1]\n",
    "    pre_pos_vc = pre_pos.value_counts()\n",
    "    native_pos = align_pos\n",
    "    if '-' in pre_pos_vc:\n",
    "        native_pos -= pre_pos_vc['-']\n",
    "    return native_pos\n",
    "# gap_dict, unique_gaps, unique_subs = species_gaps_dict(align_df)\n",
    "# force_with_shifts(align_df,test_species,\"P39T\",gap_dict,unique_gaps)\n",
    "# force_with_shifts(align_df,test_species,\"R51R\",gap_dict,unique_gaps)\n",
    "# subs = {39:(\"P\",\"T\")}\n",
    "# align_row = align_df.loc[test_species]\n",
    "# print(seq_to_align_pos(15,test_species,gap_dict)) #Example tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_columns = 999\n",
    "# display(final_align_df.loc[:,:50])\n",
    "# npos = align_pos_to_native_pos(final_align_df,test_species,36)\n",
    "# print(npos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a range of sliding window positions to consider. All sliding windows of length n in this range should #\n",
    "#include pos and not produce IndexErrors. If there is a gap at pos, then the sliding window extends one more in each direction\n",
    "#1-indexed to match generated dataframes \n",
    "def sw_list(pos,align_len,gaps,n=7):\n",
    "    if pos-n < 1:\n",
    "        sw = list(range(1,pos+n))\n",
    "    elif pos+n > align_len:\n",
    "        sw = list(range(pos-n+1,align_len+1))\n",
    "    else:\n",
    "        sw = list(range(pos-n+1,pos+n))\n",
    "    for gap in gaps: \n",
    "        if gap in sw:\n",
    "            first,last = sw[0],sw[-1]\n",
    "            if gap < pos and first > 1:\n",
    "                sw.remove(gap)\n",
    "                sw.insert(0,first-1)\n",
    "            elif gap == pos:\n",
    "                pass\n",
    "                #TODO\n",
    "            else:\n",
    "                sw.remove(gap)\n",
    "                if last+1 <= align_len:\n",
    "                    sw.append(last+1)\n",
    "                else:\n",
    "#                     print(\"boop\")\n",
    "                    sw.insert(0,first-1)\n",
    "#                 print(sw_)\n",
    "    pos_idx = sw.index(pos)\n",
    "    if pos_idx > 6:\n",
    "        return sw[pos_idx-n+1:]\n",
    "    elif len(sw) - pos_idx > 6:\n",
    "        return sw[:pos_idx+7]\n",
    "    else:\n",
    "        return sw\n",
    "\n",
    "def drop_gaps(score_series,gaps):\n",
    "    copy = score_series.copy()\n",
    "    for gap in gaps:\n",
    "        if gap in copy.index:\n",
    "            copy.drop(gap,inplace=True)\n",
    "    return copy\n",
    "#Returns both the 1-indexed list of positions of max score sliding window and the mean score for that sliding window \n",
    "#Ignore gap columns from mean score\n",
    "def max_sw(score_series, sw_, gaps, n=7):\n",
    "    sw_series = score_series[sw_]\n",
    "    sw_series = drop_gaps(sw_series,gaps)\n",
    "    sw_nd = sw_series.values\n",
    "    size = len(sw_nd)-n+1\n",
    "    sum_arr = []\n",
    "    if size > 0:\n",
    "        for i in range(size):\n",
    "            sum_arr.append(np.mean(sw_nd[i:i+n]))\n",
    "        max_nd_idx = np.argmax(sum_arr)\n",
    "        avg_score = sum_arr[max_nd_idx]\n",
    "        window = sw_series.index[max_nd_idx:max_nd_idx+n] \n",
    "    else: \n",
    "        avg_score = np.mean(sw_nd)\n",
    "        window = sw_series.index\n",
    "    return window,avg_score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cell for sliding window ranges and max score checking \n",
    "# test_srs = pd.Series([0,0,2,1,1,3,2,1,2,1,1,0,0,0,0,0,0,0,1,2,1,1,1,],index=range(1,24))\n",
    "# swr = sw_list(5,len(test_srs),[])\n",
    "# print(swr)\n",
    "# gap_positions = [12,13]\n",
    "# max_sw(test_srs,swr,gap_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized seq weights\n",
    "#Calculates Henikoff (1994) sequence weights form msa\n",
    "from collections import Counter \n",
    "def calculate_sequence_weights(msa,aas):\n",
    "    \"\"\" Calculate the sequence weights using the Henikoff '94 method\n",
    "    for the given msa. \"\"\"\n",
    "    n = len(msa)\n",
    "    alignlen = len(msa[0])\n",
    "    seq_weights = np.zeros((n))\n",
    "    for col in msa.T:\n",
    "        freqs = Counter(col)\n",
    "        del freqs['-']\n",
    "        num_observed = len(freqs)\n",
    "        \n",
    "#         d_ = [freqs[aa]*num_observed if aa != '-' else 0 for aa in col]\n",
    "        d_ = [freqs[aa]*num_observed for aa in col]\n",
    "        inverse = [1/d if d>0 else 0 for d in d_]\n",
    "        seq_weights += inverse\n",
    "    seq_weights /= alignlen\n",
    "    return seq_weights\n",
    "# seq_weights = calculate_sequence_weights(align_nd,aas)\n",
    "\n",
    "#Test works yay\n",
    "# test = np.array([['G','Y','V','G','S'],['G','F','D','G','F'],['G','Y','D','G','F'],['G','Y','Q','G','G']])\n",
    "# calculate_sequence_weights(test,aas)\n",
    "#Checked against values and examples provided in the Henikoff paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates Pc distribution for column c. Distribution is weighted \n",
    "def weighted_fcpseudo(col, seq_weights, pc_amount=0.000001):\n",
    "    if len(seq_weights) != len(col):\n",
    "        return [1]*len(col)\n",
    "    else:\n",
    "        freqs = np.array([pc_amount]*len(aas))\n",
    "        for i,aa in enumerate(aas):\n",
    "#             print(col)\n",
    "#             print([seq_weights[j] if aa == entry else 0 for j,entry in enumerate(col)])\n",
    "            freqs[i] += sum([seq_weights[j] if aa == entry else 0 for j,entry in enumerate(col)])\n",
    "        for i,entry in enumerate(freqs): \n",
    "#             if entry > pc_amount:\n",
    "#                  freqs[i] -= pc_amount\n",
    "            freqs[i] /= (sum(seq_weights) + len(aas)*pc_amount)\n",
    "        return freqs\n",
    "# test_col = [\"G\",\"Y\",\"T\",\"-\"]\n",
    "# test_col = [\"M\",\"M\",\"M\",\"M\"]\n",
    "# weights = calculate_sequence_weights(test,aas)\n",
    "# test_ = weighted_fcpseudo(test_col,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_gap_penalty(col,weights):\n",
    "    #Return simple gap penalty multiplier for column \n",
    "    gap_weights = np.array([w if c == \"-\" else 0 for c,w in zip(col,weights)])\n",
    "    gap_sum = sum(gap_weights)\n",
    "    return 1 - (gap_sum/sum(weights))\n",
    "# print(weighted_gap_penalty(['A','A','-'],[0.3333,0.3333,0.3333]))\n",
    "def relative_entropy(pC,bg,gap_penalty=0):\n",
    "    \"\"\"Calculate the relative entropy of the column distribution with a \n",
    "    background distribution specified in bg_distr. This is similar to the \n",
    "    approach proposed in Wang and Samudrala 06.\"\"\"\n",
    "    if len(bg) == 20 and len(pC) == 21:\n",
    "        #Remove gap count\n",
    "        pC = pC[:-1]\n",
    "        pC = pC/(sum(pC))\n",
    "    ratio = pC/bg\n",
    "    log_ratio = np.log(ratio)/np.log(2)\n",
    "    RE = sum([a*b for a,b in zip(pC,log_ratio)])\n",
    "    if gap_penalty:\n",
    "        RE*= gap_penalty\n",
    "    return RE\n",
    "\n",
    "def col_RE(col,bg,weights,gap_penalty=1):\n",
    "    pC = weighted_fcpseudo(col,weights)\n",
    "    if len(bg) == 20 and len(pC) == 21:\n",
    "        pC = pC[:-1]\n",
    "        pC /= sum(pC)\n",
    "    ratio = pC/bg\n",
    "    log_ratio = np.log(ratio)/np.log(2)\n",
    "    RE = sum([a*b for a,b in zip(pC,log_ratio)])\n",
    "    if gap_penalty:\n",
    "        RE*= gap_penalty\n",
    "    return RE\n",
    "# relative_entropy(np.array([0.25,0.25,0.25,0.25]),np.array([0.1,0.1,0.1,0.7]))\n",
    "\n",
    "def JSD(col,bg,weights,gap_penalty=1,jsd_lam=0.5):\n",
    "    pC = weighted_fcpseudo(col,weights)\n",
    "    if len(bg) == 20:\n",
    "        #Remove gap count\n",
    "        pC = pC[:-1]\n",
    "        pC = pC/(sum(pC))\n",
    "    gap_penalty = weighted_gap_penalty(col,weights)\n",
    "    r_dist = np.array([jsd_lam*aa for aa in pC]) + np.array([(1-jsd_lam)*aa for aa in bg])\n",
    "\n",
    "    RE_pCr = relative_entropy(pC,r_dist,gap_penalty)\n",
    "    RE_qr = relative_entropy(bg,r_dist, gap_penalty)\n",
    "    jsd = jsd_lam*RE_pCr + (1-jsd_lam)*RE_qr\n",
    "    return jsd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_z_scores(scores):\n",
    "#     if type(scores) == pd.Series:\n",
    "#         scores = scores.values\n",
    "    mean = np.mean(scores)\n",
    "    std = np.std(scores)\n",
    "    z_scores = (scores-mean)/std\n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a Jensen Shannon Difference Series for position indices within the MSA\n",
    "def generate_jsd_series(test_species,align_df, alignlen, aas,blosum62_bg):\n",
    "    jsd_srs = pd.Series(index=range(1,alignlen))\n",
    "    jsd_lam = 0.5\n",
    "    gap_threshold = 0.3\n",
    "    gap_positions = []\n",
    "    jsd_df = align_df.drop(test_species,axis=0)\n",
    "    # jsd_df = align_df.copy()\n",
    "    jsd_nd = jsd_df.values\n",
    "    weights = calculate_sequence_weights(jsd_nd,aas)\n",
    "    # print(weights)\n",
    "    for i,col in enumerate(jsd_nd.T):\n",
    "        gap_penalty = weighted_gap_penalty(col,weights)\n",
    "        jsd = JSD(col,blosum62_bg,weights,gap_penalty)\n",
    "        jsd_srs[i+1] = jsd\n",
    "        if gap_ratio(col) > gap_threshold:\n",
    "            gap_positions.append(i+1)\n",
    "    jsd_zscores = calc_z_scores(jsd_srs)\n",
    "    with pd.option_context(\"display.max_rows\",None,\"display.max_columns\", None):\n",
    "#         display(jsd_srs)\n",
    "        pass\n",
    "    return jsd_srs, jsd_zscores, gap_positions\n",
    "    #     display(z_scores)\n",
    "    #     display(jsd_df)\n",
    "#     print(gap_positions)\n",
    "# jsd_srs, jsd_zscores, gap_positions = generate_jsd_series(align_df, alignlen, aas,blosum62_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sliding window calculations\n",
    "def calc_sw_metrics(score_srs, uniques, gap_positions, alignlen, config,n=7):\n",
    "    mean = np.mean(score_srs)\n",
    "    std = np.std(score_srs)\n",
    "    display_windows = config.getboolean(\"SW_verbose\")\n",
    "\n",
    "#     print(\"Sliding Window Length: \"+str(n))\n",
    "#     print(\"Score Mean: \"+str(mean))\n",
    "#     print(\"Score Standard Deviation: \"+str(std))\n",
    "    unique_positions = uniques.columns\n",
    "    pos_jsds = score_srs.loc[unique_positions]\n",
    "    pos_jsd_zs = (pos_jsds-mean)/std\n",
    "    sw_jsds = pd.Series(index=unique_positions,name=\"Sliding Window Max Mean\")\n",
    "    sw_zs = pd.Series(index=unique_positions,name=\"Sliding Window Z Score\")\n",
    "    sw_indices = pd.Series(index=unique_positions,name=\"Start\",dtype=int)\n",
    "    for sub in uniques:\n",
    "#         sw_ = sw_list(sub,alignlen,gap_positions,n)\n",
    "#         window, window_score = max_sw(score_srs,sw_,gap_positions)\n",
    "#         sw_indices[sub] = str(list(window))\n",
    "#         sw_jsds[sub] = window_score\n",
    "#         sw_df = align_df.loc[:,window]\n",
    "#         window_z = (window_score-mean)/std\n",
    "#         sw_zs[sub] = window_z\n",
    "#         pos_jsd = jsd_srs[sub]\n",
    "#         pos_z = (pos_jsd-mean)/std\n",
    "#         if display_windows:\n",
    "#             print(\"Position: \"+str(sub))\n",
    "#             print(\"Max Score Sliding Window: \")\n",
    "#             display(sw_df)\n",
    "#             print(\"Mean JSD for window: \"+str(window_score))\n",
    "#             print(\"Z score of mean JSD: \"+str(window_z))\n",
    "#             print(\"Position JSD: \" + str(pos_jsd))\n",
    "#             print(\"Z score of position JSD: \"+str(pos_z))\n",
    "#             print(\"===============================================\")\n",
    "#     metrics = (pos_jsds, pos_jsd_zs, sw_scores, sw_zscores, sw_indices)\n",
    "        pass\n",
    "    data_dict = {\"JSD\":pos_jsds, \"JSD Z-Score\": pos_jsd_zs,\"Window JSD\": sw_jsds, \"Window JSD Z-Score\":sw_zs, \"Window\":sw_indices}\n",
    "    metrics = pd.DataFrame(index = unique_positions,data=data_dict)\n",
    "    return metrics \n",
    "# sw_metrics = calc_sw_metrics(jsd_srs, uniques, gap_positions,alignlen, config)\n",
    "# pos_jsds, pos_jsd_zs, sw_scores, sw_zscores, sw_indices = sw_metrics\n",
    "# print(pos_jsds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary table\n",
    "def summary_table(align_df, sw_metrics,test_species,blos_df, display_summary):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     display_summary = config.getboolean(\"Summary_verbose\")\n",
    "    pos_jsds, pos_jsd_zs, sw_scores, sw_zscores, sw_indices = sw_metrics\n",
    "    jsd_nd = align_df.copy().drop(index=test_species).values\n",
    "#     unique_positions = uniques.columns\n",
    "    unique_positions = sw_metrics.columns\n",
    "    align_nd = align_df.values\n",
    "    gap_ratios, test_variants, sub_freq = pd.Series(index=unique_positions), pd.Series(index=unique_positions), \\\n",
    "                 pd.Series(index=unique_positions,dtype=int)\n",
    "#     test_variants = pd.Series(index=unique_positions)\n",
    "#     sub_freq = pd.Series(index=unique_positions,dtype=int)\n",
    "    blosum62_col = pd.Series(index=unique_positions,dtype=np.float64)\n",
    "    blosum62_pairwise = pd.Series(index=unique_positions)\n",
    "    for pos in unique_positions:\n",
    "        pos_jsds, pos_jsdzs = sw_metrics.loc[:,\"JSD\"], sw_metrics.loc[:,\"JSD Z-Score\"]\n",
    "        align_col = align_nd.T[pos-1]\n",
    "        align_col_srs = align_df.loc[:,pos]\n",
    "        n_seq = len(align_col_srs)\n",
    "        gap_ratios[pos] = gap_ratio(align_col)\n",
    "        test_species_variant = align_df.loc[test_species,pos]\n",
    "        test_variants[pos] = test_species_variant\n",
    "        vc = align_df[pos].value_counts()\n",
    "        sub_freq[pos] = vc[test_species_variant]\n",
    "        col = jsd_nd.T[pos-1]\n",
    "        if not test_species_variant == '-':\n",
    "            blos_sum = np.mean(blos_df[test_species_variant][col])\n",
    "            blosum62_col[pos] = blos_sum\n",
    "        else:\n",
    "            blosum62_col[pos] = np.nan\n",
    "        outgrp_vars, outgrp_counts = np.unique(col,return_counts=True)\n",
    "        \n",
    "        #pairwise calculations\n",
    "        others_col = jsd_nd.T[pos-1]\n",
    "        pairwise_scores = []\n",
    "        skip_chars = ['-','X']\n",
    "        for i,first in enumerate(others_col):\n",
    "            for j,second in enumerate(others_col):\n",
    "                if i<j:\n",
    "                    if not first in skip_chars and not second in skip_chars:\n",
    "                        pairwise_scores.append(blos_df[first][second])\n",
    "                    else: \n",
    "                        pass\n",
    "        if pairwise_scores:\n",
    "            blosum62_pairwise[pos] = np.mean(pairwise_scores)\n",
    "        else:\n",
    "            blosum62_pairwise[pos] = np.nan\n",
    "\n",
    "    data = {\"Test Variant\":test_variants,\"Variant Instances\":sub_freq,\"Window Positions\":sw_indices, \\\n",
    "            \"Gap Fraction\":gap_ratios, \"JSD\":pos_jsds,\"JSD Z-Score\":pos_jsd_zs,\\\n",
    "            \"Window Z-Score\":sw_zscores, \"Test vs Outgroup Blosum62\":blosum62_col, \\\n",
    "            \"Outgroup Pairwise Blosum62\":blosum62_pairwise}\n",
    "    summary_df = pd.DataFrame(index=unique_positions,data=data)\n",
    "    filterthreshold = 0.4\n",
    "    filtered = summary_df[summary_df[\"Window Z-Score\"] >= filterthreshold]\n",
    "    #Output conditional on config option\n",
    "    if display_summary:\n",
    "        print(test_species+\" Semi-Unique Substitutions and Sliding Window Scores\")\n",
    "        print(\"Number of Species: \"+str(len(align_df.index)))\n",
    "        print(\"Positions with gap percentages over 0.3 were omitted from sliding window calculations\")\n",
    "        with pd.option_context(\"display.max_rows\",None,\"display.max_columns\", None,\"display.max_colwidth\",200):\n",
    "            display(summary_df)\n",
    "        \n",
    "        print(\"Filtered to Window Z-Score Threshold of \"+str(filterthreshold))\n",
    "        with pd.option_context(\"display.max_rows\",None,\"display.max_columns\", None,\"display.max_colwidth\",200):\n",
    "            display(filtered)\n",
    "#             pass\n",
    "    return summary_df\n",
    "# display_summary = config.getboolean(\"Summary_verbose\")\n",
    "# summary_df = summary_table(align_df,uniques,sw_metrics,test_species,blos_df,display_summary)\n",
    "\n",
    "def summary_table2(align_df, sw_metrics,test_species,blos_df, display_summary):\n",
    "#     pos_jsds, pos_jsd_zs, sw_scores, sw_zscores, sw_indices = sw_metrics\n",
    "    pos_jsds, pos_jsdzs = sw_metrics.loc[:,\"JSD\"], sw_metrics.loc[:,\"JSD Z-Score\"]\n",
    "    jsd_nd = align_df.copy().drop(index=test_species).values\n",
    "    unique_positions = sw_metrics.index\n",
    "    unique_positions.name = \"MSA Position\"\n",
    "    n_seq = len(align_df.index)\n",
    "    cols_list = [\"Test Species Position\", \"Test Variant\",\"Test Variant Instances\",\"Outgroup Variant\",\\\n",
    "                 \"Outgroup Variant Instances\",\"Aligned Sequences\", \"Gap Fraction\", \"JSD\",\"JSD Z-Score\", \\\n",
    "                 \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "    summary_df = pd.DataFrame(index=unique_positions,columns=cols_list)\n",
    "    for pos in unique_positions:\n",
    "        native_pos = align_pos_to_native_pos(align_df, test_species,pos)\n",
    "        jsd = pos_jsds[pos]\n",
    "        jsd_z = pos_jsdzs[pos]\n",
    "        align_col_srs = align_df.loc[:,pos]\n",
    "        align_col = align_col_srs.values\n",
    "        outgroup_variant = align_col_srs.mode().iloc[0]\n",
    "        gap_fraction = gap_ratio(align_col)\n",
    "        test_variant = align_df.loc[test_species,pos]\n",
    "        vc = align_df[pos].value_counts()\n",
    "        og_var_freq = vc[outgroup_variant]\n",
    "        test_var_freq = vc[test_variant]\n",
    "        col = jsd_nd.T[pos-1]\n",
    "        if not test_variant == '-':\n",
    "            blos_mean = np.mean(blos_df[test_variant][col])\n",
    "        else:\n",
    "            blos_mean = np.nan\n",
    "        #pairwise calculations\n",
    "        others_col = jsd_nd.T[pos-1]\n",
    "        pairwise_scores = []\n",
    "        skip_chars = ['-','X']\n",
    "        for i,first in enumerate(others_col):\n",
    "            for j,second in enumerate(others_col):\n",
    "                if i<j:\n",
    "                    if not first in skip_chars and not second in skip_chars:\n",
    "                        pairwise_scores.append(blos_df[first][second])\n",
    "                    else: \n",
    "                        pass\n",
    "        if pairwise_scores:\n",
    "#             blosum62_pairwise[pos] = np.mean(pairwise_scores)\n",
    "            blos_pw = np.mean(pairwise_scores)\n",
    "        else:\n",
    "            blos_pw = np.nan\n",
    "        row_values = [native_pos, test_variant, test_var_freq,outgroup_variant,og_var_freq,n_seq,gap_fraction,jsd,jsd_z,blos_mean,blos_pw]\n",
    "        summary_row = pd.Series(name=pos,data=dict(zip(cols_list,row_values)))\n",
    "#         summary_df = summary_df.append(summary_row)\n",
    "        summary_df.loc[pos] = summary_row\n",
    "    #Output conditional on config option\n",
    "    if display_summary:\n",
    "        print(test_species+\" Semi-Unique Substitutions Summary\")\n",
    "        print(\"Number of Species: \"+str(len(align_df.index)))\n",
    "        with pd.option_context(\"display.max_rows\",None,\"display.max_columns\", None,\"display.max_colwidth\",200):\n",
    "            display(summary_df)\n",
    "#             pass\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Display Alignment Table and Unique subs for Reference\n",
    "# with pd.option_context(\"display.max_rows\",None,\"display.max_columns\", None):\n",
    "# #     display(align_df)\n",
    "# #     display(uniques)\n",
    "# #     display(align_df)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_summary_output(summary_path, gene_name, window_calculations=False, filter_output=False):\n",
    "    #Reads summary data from previous run from csv file\n",
    "    #Filtering optional\n",
    "    #Formats so that can be readily appended to overall_summary (reindexes, includes gene name)\n",
    "    filter_output = False\n",
    "    summary_df = pd.read_csv(summary_path,index_col=0)\n",
    "    summary_df.reset_index(drop=False,inplace=True)\n",
    "    summary_df.rename(columns={\"index\":\"Position\"},inplace=True)\n",
    "    if \"Gene\" not in summary_df.columns:\n",
    "        summary_df.insert(0,\"Gene\",[gene_name]*len(summary_df))\n",
    "    if filter_output:    \n",
    "        filtered = filter_summary(gene_name,summary_df, window_calculations)\n",
    "        if len(filtered) < 1:\n",
    "            print(\"No results above Z-threshold/ gap fraction threshold\")\n",
    "        else:\n",
    "            print(\"Filtered to Z-threshold = 0.6, or gap fraction > 0.85:\")\n",
    "            return filtered\n",
    "    else:\n",
    "        return summary_df\n",
    "def write_output(gene_name,run_name,MSA_outfile,summary_df):\n",
    "    #Writes out MSA as a clustal format \n",
    "    create_directory(run_name+\"/output/\"+gene_name)\n",
    "    MSA_path = run_name+\"/output/\"+gene_name+\"/\"+gene_name+\".fasta\"\n",
    "#     records_generator = SeqIO.parse(open(MSA_outfile),\"fasta\")\n",
    "    SeqIO.convert(MSA_outfile,\"fasta\",MSA_path,\"fasta\")\n",
    "    summary_path = run_name+\"/output/\"+gene_name+\"/\"+gene_name+\"_summary.csv\"\n",
    "    summary_df.to_csv(summary_path)\n",
    "    \n",
    "def write_output2(gene_name,run_name,records_df,summary_df=pd.DataFrame()):\n",
    "    align_srs = records_df[\"align\"]\n",
    "    gene_dir_path = run_name+\"/output/{0}\".format(gene_name)\n",
    "    create_directory(gene_dir_path)\n",
    "    align_path = gene_dir_path+\"/{0}\".format(gene_name)+\"_MSA.fasta\"\n",
    "    std_path = gene_dir_path+\"/{0}\".format(gene_name)+\".fasta\"\n",
    "    srs_to_fasta(align_srs,align_path)\n",
    "    align_srs_to_seq_srs(align_srs, outfile_path=std_path)\n",
    "    drop_align = records_df.drop(columns=\"align\",inplace=False)\n",
    "    records_path = gene_dir_path+\"/{0}\".format(gene_name)+\"_records.csv\"\n",
    "    drop_align.to_csv(records_path,float_format='%.5f')\n",
    "    if not summary_df.empty:\n",
    "        summary_path = gene_dir_path+\"/{0}\".format(gene_name)+\"_summary.csv\"\n",
    "        summary_df.to_csv(summary_path,float_format='%.5f')\n",
    "        \n",
    "def write_output3(gene_name,run_name,records_df,summary_df=pd.DataFrame()):\n",
    "    \"\"\".fasta file output writing (both pre and post alignment) are now handled during \n",
    "    process_input (specifically in seq_srs_to_align_df by calling construct_id_dm)\"\"\"\n",
    "    gene_dir_path = \"{0}/output/{1}\".format(run_name,gene_name)\n",
    "#     create_directory(gene_dir_path)\n",
    "    drop_align = records_df.drop(columns=\"seq\",inplace=False)\n",
    "#     display(drop_align)\n",
    "    records_path = \"{0}/{1}_records.csv\".format(gene_dir_path,gene_name)\n",
    "    drop_align.to_csv(records_path,float_format='%.5f')\n",
    "    if not summary_df.empty:\n",
    "        summary_path = \"{0}/{1}_summary.csv\".format(gene_dir_path,gene_name)\n",
    "        summary_df.to_csv(summary_path,float_format='%.5f')\n",
    "        \n",
    "def write_output4(records_fpath,summary_fpath,records_df=pd.DataFrame(),summary_df=pd.DataFrame(),write_seq=False):\n",
    "    \"\"\".fasta file output writing (both pre and post alignment) are now handled during \n",
    "    process_input (specifically in seq_srs_to_align_df by calling construct_id_dm)\"\"\"\n",
    "    if not records_df.empty:\n",
    "        if not write_seq and \"seq\" in records_df:\n",
    "            drop_seq = records_df.drop(columns=\"seq\",inplace=False)\n",
    "            drop_seq.to_csv(records_fpath,float_format='%.5f')\n",
    "        else:\n",
    "            records_df.to_csv(records_fpath,float_format='%.5f')\n",
    "    if not summary_df.empty:\n",
    "#         summary_path = \"{0}/{1}_summary.csv\".format(gene_dir_path,gene_name)\n",
    "        summary_df.to_csv(summary_fpath,float_format='%.5f')        \n",
    "        \n",
    "\n",
    "def filter_summary(gene_name, summary_df, window_calculations=True,jsd_thresh=0.6, gap_thresh=0.85):\n",
    "    overall_add = summary_df.copy()\n",
    "    filtered = overall_add[overall_add[\"JSD Z-Score\"] > jsd_thresh]\n",
    "    filtered = filtered.append(overall_add.loc[(overall_add[\"Gap Fraction\"] > gap_thresh) & ~(overall_add[\"Test Variant\"] == '-')])\n",
    "#     filtered.reset_index(drop=False,inplace=True)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old input schema - \n",
    "# #Input parsing and background distribution information\n",
    "# DEFAULT_SPECIES_PATH = \"config/v10_0_species.txt\"\n",
    "# aas, blosum62_bg, blos_df, sim_matrix = gen_blos_df()\n",
    "# config = parse_config()\n",
    "# run_name = config[\"RunName\"]\n",
    "# create_run_directory(run_name)\n",
    "# spec_list, spec_hc = parse_species(DEFAULT_SPECIES_PATH)\n",
    "# write_run_params_file(config, DEFAULT_SPECIES_PATH, spec_hc)\n",
    "# genes_file = config[\"GenesFile\"]\n",
    "# gene_list = parse_genes(genes_file)\n",
    "# tax_table = odb_tablev10(spec_list)\n",
    "\n",
    "# UNIQUE_THRESH = 0.1\n",
    "# DROP_SPEC_LIST = [\"10141_0\",\"13616_0\",\"9258_0\",\"9483_0\",\"9544_0\",\"9598_0\",\"9685_0\",\"43346_0\",\"246437_0\",\"9925_0\",\\\n",
    "#                  \"9940_0\",\"9646_0\",\"74533_0\",\"9365_0\",\"9785_0\",\"34839_0\"]\n",
    "\n",
    "# #Config Settings invariant of gene; creation of subfolders for run\n",
    "# test_species_name = config[\"TestSpecies\"]\n",
    "# display_MSA = config.getboolean(\"MSA_verbose\")\n",
    "# display_uniques = config.getboolean(\"Uniques_verbose\")\n",
    "# display_summary = config.getboolean(\"Summary_Verbose\")\n",
    "# errors_fpath = '{0}/summary/errors.tsv'.format(run_name)\n",
    "# seq_qc_fpath = '{0}/summary/seq_QC.tsv'.format(run_name)\n",
    "# if os.path.exists(errors_fpath):\n",
    "#     check_errors = True\n",
    "#     errors_df = pd.read_csv(errors_fpath,delimiter=\"\\t\",index_col=\"gene\")\n",
    "#     error_genes = errors_df.index\n",
    "# else:\n",
    "#     check_errors = False\n",
    "# #Acquire input\n",
    "# valid_searches, failed_searches = download_input_data(gene_list,tax_table,config) \n",
    "# #Run analysis for each gene in genes list\n",
    "# window_calculations = False\n",
    "# OVERWRITE_ANALYSIS = False\n",
    "# if window_calculations:\n",
    "#     summary_cols = [\"Gene\",\"Position\",\"Test Variant\",\"Test Variant Instances\",\"Window Positions\", \"Gap Fraction\",\\\n",
    "#                     \"JSD\",\"JSD Z-Score\",\"Window Z-Score\", \\\n",
    "#                     \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "# else:\n",
    "#     summary_cols = [\"Gene\",\"Test Species Position\",\"MSA Position\",\"Test Variant\",\"Test Variant Instances\",\\\n",
    "#                     \"Outgroup Variant\", \"Aligned Sequences\", \"Gap Fraction\", \"JSD\",\"JSD Z-Score\", \\\n",
    "#                      \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "# numeric_cols = [\"Gap Fraction\",\"JSD\",\"JSD Z-Score\", \\\n",
    "#                 \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "# overall_summary = pd.DataFrame(columns=summary_cols)\n",
    "# # for col in numeric_cols:\n",
    "# #     overall_summary[col] = overall_summary[col].astype(np.float64)\n",
    "# for gene_name in valid_searches[:]:\n",
    "# # for gene_name in [\"ATPIF1\",\"ATP5A1\",\"COX6B1\"]:\n",
    "#     empty_directory(\"tmp\")\n",
    "#     print(\"=========\"+gene_name+\"=========\")\n",
    "#     summary_path = run_name+\"/output/\"+gene_name+\"/\"+gene_name+\"_summary.csv\"\n",
    "#     if check_errors and gene_name in error_genes:#error_genes.str.contains(gene_name).any():\n",
    "#         error_row = errors_df.loc[gene_name,:]\n",
    "#         error_type, error_code, error_str = error_row.values\n",
    "#         print(\"{0}\\t{1}\\t{2}\\t{3}\".format(gene_name,error_type,error_code,error_str))\n",
    "#     elif os.path.exists(summary_path) and not OVERWRITE_ANALYSIS:\n",
    "#         summary_df = read_summary_output(summary_path,gene_name,window_calculations)\n",
    "#         overall_summary = overall_summary.append(summary_df,sort=False)\n",
    "#     else:\n",
    "#         try:\n",
    "#             final_records_df, final_align_df = process_input(gene_name,run_name,test_species,errors_fpath,seq_qc_fpath,drop_spec_list=DROP_SPEC_LIST)            \n",
    "#             test_species_record = final_records_df.loc[final_records_df[\"organism_name\"]==test_species_name,:]\n",
    "#             test_species_id = test_species_record.index[0]\n",
    "#         except (OrthoDBQueryError, SequenceDataError) as e:\n",
    "#             write_errors(errors_fpath,gene_name,e)\n",
    "#             continue\n",
    "#         n, align_len = len(final_align_df.index), len(final_align_df.columns)\n",
    "#         #Unique substitutions must be present in <20% of sequences\n",
    "#         sub_freq_threshold = max(int(n*UNIQUE_THRESH), 1)\n",
    "#         uniques = find_uniques(final_align_df,sub_freq_threshold,test_species_id,display_uniques)\n",
    "#         if len(uniques.columns) == 0:\n",
    "#             SA_error = SequenceAnalysisError(0,\"No species unique substitutions under occurence threshold ({0}%)\".format(100*UNIQUE_THRESH))\n",
    "#             write_errors(errors_fpath,gene_name,SA_error)\n",
    "#             write_output3(gene_name,run_name,final_records_df)\n",
    "#             continue\n",
    "#         else:\n",
    "#             align_nd = final_align_df.values\n",
    "#             seq_weights = calculate_sequence_weights(align_nd,aas)\n",
    "#             #Unique substitution identification, metrics calculations and individual gene output writing\n",
    "#             gap_dict, unique_gaps, unique_subs = species_gaps_dict(final_align_df)\n",
    "#             jsd_srs, jsd_zscores, gap_positions = generate_jsd_series(test_species_id,final_align_df,align_len,aas,blosum62_bg)\n",
    "#             sw_metrics = calc_sw_metrics(jsd_srs, uniques, gap_positions,align_len, config)\n",
    "#             if window_calculations:\n",
    "#                 summary_df = summary_table(final_align_df,sw_metrics,test_species_id,blos_df,display_summary)\n",
    "#             else:\n",
    "#                 summary_df = summary_table2(final_align_df,sw_metrics,test_species_id,blos_df,display_summary)\n",
    "#             write_output3(gene_name,run_name,final_records_df,summary_df)\n",
    "#             summary_df.reset_index(drop=False,inplace=True)\n",
    "#             if not \"Gene\" in summary_df.columns:\n",
    "#                 summary_df.insert(0,\"Gene\",[gene_name]*len(summary_df))\n",
    "#             overall_summary = overall_summary.append(summary_df,sort=False)\n",
    "# overall_summary.reset_index(drop=True,inplace=True)\n",
    "# overall_summary = overall_summary[summary_cols]\n",
    "# display(overall_summary)\n",
    "# # if window_calculations:\n",
    "# #     ordered_cols = [\"Gene\",\"Position\",\"Test Variant\",\"Variant Instances\",\"Gap Fraction\",\"Position JSD\",\\\n",
    "# #                     \"Position JSD Z-Score\",\"Test vs Outgroup Blosum62\",\"Outgroup Pairwise Blosum62\",\\\n",
    "# #                     \"Window Positions\",\"Window Z-Score\"]\n",
    "# # else:\n",
    "# #     ordered_cols = [\"Gene\",\"Position\",\"Test Variant\",\"Variant Instances\",\"Gap Fraction\",\"Position JSD\",\\\n",
    "# #                     \"Position JSD Z-Score\",\"Test vs Outgroup Blosum62\",\"Outgroup Pairwise Blosum62\",\\\n",
    "# #                     \"Window Positions\",\"Window Z-Score\"]\n",
    "# # overall_summary = overall_summary[ordered_cols]\n",
    "# # overall_summary.rename(columns={\"index\":\"Position\"},inplace=True)\n",
    "# # display(overall_summary)\n",
    "# overall_summary_path = run_name+\"/summary/summary.csv\"\n",
    "# overall_summary.to_csv(overall_summary_path,float_format='%.5f')\n",
    "# plt.scatter(x=overall_summary[\"JSD\"],y=overall_summary[\"Test vs Outgroup Blosum62\"],alpha=0.2)\n",
    "# plt.xlabel(\"Position JSD\")\n",
    "# plt.ylabel(\"Average Test Species vs Outgroup Blosum62\")\n",
    "# plt.title(\"Distribution of JSD/ Blosum for all input unique subs\")\n",
    "# plt.savefig(run_name+\"/summary/summary_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>error_code</th>\n",
       "      <th>error_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CDC42</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>1</td>\n",
       "      <td>OrthoDB search yielded too many clusters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GABP1</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSF2B</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLFR710A</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDIA3P1</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMCHL2</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPL112</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLC6A10P</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAD14</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UBE2D3-AS1</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CACB1</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBR3-AS1</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD151</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLEC2D</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFRS7</th>\n",
       "      <td>OrthoDBQueryError</td>\n",
       "      <td>0</td>\n",
       "      <td>No OrthoDB results for query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EIF3CL</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALAT1</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>0</td>\n",
       "      <td>No reference sequences could be found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT1F</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>0</td>\n",
       "      <td>No reference sequences could be found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT3</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPL23AP64</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>0</td>\n",
       "      <td>No reference sequences could be found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPL39L</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>1</td>\n",
       "      <td>Test Species has no sequence in input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPL41</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMOD2</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF91</th>\n",
       "      <td>SequenceDataError</td>\n",
       "      <td>4</td>\n",
       "      <td>Test Species has no reference sequence in inpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   error_type  error_code  \\\n",
       "gene                                        \n",
       "CDC42       OrthoDBQueryError           1   \n",
       "GABP1       OrthoDBQueryError           0   \n",
       "HSF2B       OrthoDBQueryError           0   \n",
       "OLFR710A    OrthoDBQueryError           0   \n",
       "PDIA3P1     OrthoDBQueryError           0   \n",
       "PMCHL2      OrthoDBQueryError           0   \n",
       "RPL112      OrthoDBQueryError           0   \n",
       "SLC6A10P    OrthoDBQueryError           0   \n",
       "SMAD14      OrthoDBQueryError           0   \n",
       "UBE2D3-AS1  OrthoDBQueryError           0   \n",
       "CACB1       OrthoDBQueryError           0   \n",
       "CBR3-AS1    OrthoDBQueryError           0   \n",
       "CD151       SequenceDataError           4   \n",
       "CLEC2D      SequenceDataError           4   \n",
       "DFRS7       OrthoDBQueryError           0   \n",
       "EIF3CL      SequenceDataError           4   \n",
       "MALAT1      SequenceDataError           0   \n",
       "MT1F        SequenceDataError           0   \n",
       "MT3         SequenceDataError           4   \n",
       "RPL23AP64   SequenceDataError           0   \n",
       "RPL39L      SequenceDataError           1   \n",
       "RPL41       SequenceDataError           4   \n",
       "TMOD2       SequenceDataError           4   \n",
       "ZNF91       SequenceDataError           4   \n",
       "\n",
       "                                                    error_str  \n",
       "gene                                                           \n",
       "CDC42                OrthoDB search yielded too many clusters  \n",
       "GABP1                            No OrthoDB results for query  \n",
       "HSF2B                            No OrthoDB results for query  \n",
       "OLFR710A                         No OrthoDB results for query  \n",
       "PDIA3P1                          No OrthoDB results for query  \n",
       "PMCHL2                           No OrthoDB results for query  \n",
       "RPL112                           No OrthoDB results for query  \n",
       "SLC6A10P                         No OrthoDB results for query  \n",
       "SMAD14                           No OrthoDB results for query  \n",
       "UBE2D3-AS1                       No OrthoDB results for query  \n",
       "CACB1                            No OrthoDB results for query  \n",
       "CBR3-AS1                         No OrthoDB results for query  \n",
       "CD151       Test Species has no reference sequence in inpu...  \n",
       "CLEC2D      Test Species has no reference sequence in inpu...  \n",
       "DFRS7                            No OrthoDB results for query  \n",
       "EIF3CL      Test Species has no reference sequence in inpu...  \n",
       "MALAT1                  No reference sequences could be found  \n",
       "MT1F                    No reference sequences could be found  \n",
       "MT3         Test Species has no reference sequence in inpu...  \n",
       "RPL23AP64               No reference sequences could be found  \n",
       "RPL39L                  Test Species has no sequence in input  \n",
       "RPL41       Test Species has no reference sequence in inpu...  \n",
       "TMOD2       Test Species has no reference sequence in inpu...  \n",
       "ZNF91       Test Species has no reference sequence in inpu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========AAAS=========\n",
      "=========ABHD17C=========\n",
      "=========ACADM=========\n",
      "=========ACTR3=========\n",
      "=========ADCK5=========\n",
      "=========AGBL1=========\n",
      "=========AGO3=========\n",
      "=========AK2=========\n",
      "=========AKAP1=========\n",
      "=========AKR1A1=========\n",
      "=========ALDOA=========\n",
      "=========AMDHD2=========\n",
      "=========ANAPC4=========\n",
      "=========ANXA2=========\n",
      "=========APEX1=========\n",
      "=========ARHGAP21=========\n",
      "=========ARL6IP1=========\n",
      "=========ARPC1B=========\n",
      "=========ARVCF=========\n",
      "=========ASAH1=========\n",
      "=========ASCC2=========\n",
      "=========ASNS=========\n",
      "=========ATF1=========\n",
      "ATF1\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========ATP5G1=========\n",
      "=========ATP5G3=========\n",
      "=========ATP6V0B=========\n",
      "=========ATPIF1=========\n",
      "=========ATRX=========\n",
      "=========ATXN7L1=========\n",
      "=========BCAS1=========\n",
      "=========BRD4=========\n",
      "=========BUB3=========\n",
      "=========C14ORF132=========\n",
      "=========C19ORF53=========\n",
      "=========C6ORF165=========\n",
      "=========C7ORF57=========\n",
      "=========CACB1=========\n",
      "CACB1\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========CAD=========\n",
      "=========CALCOCO2=========\n",
      "=========CALM1=========\n",
      "=========CBFB=========\n",
      "=========CBR3-AS1=========\n",
      "CBR3-AS1\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========CBX1=========\n",
      "=========CCDC148=========\n",
      "=========CCNDBP1=========\n",
      "=========CCT7=========\n",
      "=========CD151=========\n",
      "CD151\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========CD276=========\n",
      "=========CDC20=========\n",
      "=========CDC42=========\n",
      "CDC42\tOrthoDBQueryError\t1\tOrthoDB search yielded too many clusters\n",
      "=========CDK5RAP3=========\n",
      "=========CEP135=========\n",
      "=========CFL2=========\n",
      "=========CHRM1=========\n",
      "=========CLEC2D=========\n",
      "CLEC2D\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========CLK3=========\n",
      "=========CLNS1A=========\n",
      "=========CLPB=========\n",
      "=========CMPK1=========\n",
      "=========CMTM3=========\n",
      "=========COA5=========\n",
      "=========COL4A2=========\n",
      "=========COPS2=========\n",
      "=========COPZ1=========\n",
      "=========COQ6=========\n",
      "=========CORO1A=========\n",
      "=========COX5B=========\n",
      "=========COX7C=========\n",
      "=========CPTP=========\n",
      "=========CREBZF=========\n",
      "=========CRTAP=========\n",
      "=========CSNK1G1=========\n",
      "=========CSTF3=========\n",
      "=========CYB561D2=========\n",
      "=========DAB2=========\n",
      "=========DCTN2=========\n",
      "=========DDHD2=========\n",
      "=========DDX1=========\n",
      "=========DDX31=========\n",
      "=========DFRS7=========\n",
      "DFRS7\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========DHX15=========\n",
      "=========DNAJB2=========\n",
      "=========DSCAM=========\n",
      "=========DYNLL1=========\n",
      "=========DZIP1=========\n",
      "=========ECHS1=========\n",
      "=========EEF1D=========\n",
      "=========EHMT1=========\n",
      "=========EID1=========\n",
      "=========EIF3CL=========\n",
      "EIF3CL\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========EIF3L=========\n",
      "=========EIF4B=========\n",
      "=========EMC2=========\n",
      "=========EMP3=========\n",
      "=========ENKUR=========\n",
      "=========ENO1=========\n",
      "=========ERLEC1=========\n",
      "=========FAM45A=========\n",
      "=========FBXO32=========\n",
      "=========FGFR1OP=========\n",
      "=========FH=========\n",
      "=========FIP1L1=========\n",
      "=========GABPB1=========\n",
      "=========GABRA2=========\n",
      "=========GCAT=========\n",
      "=========GDI2=========\n",
      "=========GEN1=========\n",
      "=========GHITM=========\n",
      "=========GLE1=========\n",
      "=========GNPDA1=========\n",
      "=========GORASP2=========\n",
      "=========GPC6=========\n",
      "=========GPM6B=========\n",
      "=========GPX4=========\n",
      "=========GSTP1=========\n",
      "=========GTF2H5=========\n",
      "=========HAUS2=========\n",
      "=========HDLBP=========\n",
      "=========HMGCS1=========\n",
      "=========HNRNPA2B1=========\n",
      "=========HNRNPC=========\n",
      "=========HNRNPH1=========\n",
      "=========HPDL=========\n",
      "=========HSF2B=========\n",
      "HSF2B\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========HSP90AA1=========\n",
      "=========IDH3A=========\n",
      "=========IDH3B=========\n",
      "=========IFT52=========\n",
      "=========INPP5F=========\n",
      "INPP5F\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========IPO5=========\n",
      "=========IPO8=========\n",
      "=========IRF2BP2=========\n",
      "=========ISCA2=========\n",
      "=========ISPD=========\n",
      "=========KIAA1217=========\n",
      "=========KIFC2=========\n",
      "=========KLF6=========\n",
      "=========KTN1=========\n",
      "=========LAMP2=========\n",
      "=========LAMTOR5=========\n",
      "=========LDB1=========\n",
      "=========LDHA=========\n",
      "=========LDHB=========\n",
      "=========LEO1=========\n",
      "=========LIG1=========\n",
      "=========LIMS2=========\n",
      "=========LRP6=========\n",
      "=========LRRC41=========\n",
      "=========LUC7L3=========\n",
      "=========MAEA=========\n",
      "=========MAF1=========\n",
      "=========MAGED1=========\n",
      "=========MALAT1=========\n",
      "MALAT1\tSequenceDataError\t0\tNo reference sequences could be found\n",
      "=========MANF=========\n",
      "=========MAP1A=========\n",
      "=========MARF1=========\n",
      "=========MEMO1=========\n",
      "=========MLH1=========\n",
      "=========MMP15=========\n",
      "=========MORF4L2=========\n",
      "=========MPHOSPH10=========\n",
      "=========MPP1=========\n",
      "=========MRPL15=========\n",
      "=========MRPL52=========\n",
      "=========MRPL58=========\n",
      "=========MRPS21=========\n",
      "=========MRPS25=========\n",
      "=========MRPS6=========\n",
      "=========MT1F=========\n",
      "MT1F\tSequenceDataError\t0\tNo reference sequences could be found\n",
      "=========MT3=========\n",
      "MT3\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========MTDH=========\n",
      "=========MTIF2=========\n",
      "=========NACA=========\n",
      "=========NALCN=========\n",
      "=========NDUFB5=========\n",
      "=========NDUFB9=========\n",
      "=========NDUFS1=========\n",
      "=========NDUFS2=========\n",
      "=========NDUFV1=========\n",
      "=========NEK6=========\n",
      "=========NEMF=========\n",
      "=========NF1=========\n",
      "=========NFATC3=========\n",
      "=========NIFK=========\n",
      "=========NIP7=========\n",
      "=========NMRK2=========\n",
      "=========NOP10=========\n",
      "=========NPC2=========\n",
      "=========NRBP1=========\n",
      "=========NSRP1=========\n",
      "=========NSUN4=========\n",
      "=========NUP155=========\n",
      "=========NUP85=========\n",
      "=========NUSAP1=========\n",
      "=========NXT2=========\n",
      "=========OAT=========\n",
      "=========OAZ2=========\n",
      "=========OCIAD2=========\n",
      "=========OCRL=========\n",
      "=========OLFR710A=========\n",
      "OLFR710A\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========OSCP1=========\n",
      "=========OXSR1=========\n",
      "=========P3H2=========\n",
      "=========PAFAH1B1=========\n",
      "PAFAH1B1\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========PAFAH1B2=========\n",
      "=========PANK2=========\n",
      "=========PARK7=========\n",
      "=========PARPBP=========\n",
      "=========PC=========\n",
      "=========PCCA=========\n",
      "=========PDHB=========\n",
      "=========PDIA3=========\n",
      "=========PES1=========\n",
      "=========PFDN5=========\n",
      "=========PGK1=========\n",
      "=========PHB2=========\n",
      "=========PHC2=========\n",
      "=========PHF3=========\n",
      "=========PIAS1=========\n",
      "=========PIK3CA=========\n",
      "=========PKM=========\n",
      "=========PLEC=========\n",
      "=========PLEKHG3=========\n",
      "=========PMCHL2=========\n",
      "PMCHL2\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========PMS1=========\n",
      "=========POLD2=========\n",
      "=========PPIA=========\n",
      "=========PPME1=========\n",
      "=========PPP1R3B=========\n",
      "=========PPP2CA=========\n",
      "=========PPP2R5A=========\n",
      "=========PPP4C=========\n",
      "=========PRDX3=========\n",
      "=========PREB=========\n",
      "=========PRIMPOL=========\n",
      "=========PRPF31=========\n",
      "=========PRSS23=========\n",
      "=========PRUNE1=========\n",
      "=========PSMC2=========\n",
      "=========PSMC6=========\n",
      "=========PSMD14=========\n",
      "=========PSME2=========\n",
      "=========PSME3=========\n",
      "=========PTK2=========\n",
      "=========PTP4A1=========\n",
      "=========R3HDM1=========\n",
      "=========RAB10=========\n",
      "=========RAB11B=========\n",
      "=========RAB18=========\n",
      "=========RAB2A=========\n",
      "=========RAB6A=========\n",
      "=========RALB=========\n",
      "=========RANBP1=========\n",
      "=========RANGAP1=========\n",
      "=========RASA2=========\n",
      "=========RBBP7=========\n",
      "=========RBMS1=========\n",
      "=========RBPJ=========\n",
      "=========RCC2=========\n",
      "=========RFC2=========\n",
      "=========RFC4=========\n",
      "=========RHOC=========\n",
      "=========RLF=========\n",
      "=========RPA2=========\n",
      "=========RPL112=========\n",
      "RPL112\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========RPL14=========\n",
      "=========RPL19=========\n",
      "=========RPL23AP64=========\n",
      "RPL23AP64\tSequenceDataError\t0\tNo reference sequences could be found\n",
      "=========RPL24=========\n",
      "=========RPL26=========\n",
      "=========RPL31=========\n",
      "=========RPL34=========\n",
      "=========RPL35=========\n",
      "=========RPL36=========\n",
      "=========RPL37A=========\n",
      "=========RPL39L=========\n",
      "RPL39L\tSequenceDataError\t1\tTest Species has no sequence in input\n",
      "=========RPL4=========\n",
      "=========RPL41=========\n",
      "RPL41\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========RPL6=========\n",
      "=========RPL7A=========\n",
      "=========RPL8=========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========RPS10-NUDT3=========\n",
      "RPS10-NUDT3\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========RPS12=========\n",
      "RPS12\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========RPS16=========\n",
      "=========RPS19BP1=========\n",
      "=========RPS21=========\n",
      "=========RPS29=========\n",
      "=========S100A4=========\n",
      "=========SARS=========\n",
      "=========SCAMP2=========\n",
      "=========SCAPER=========\n",
      "=========SCML2=========\n",
      "=========SCN7A=========\n",
      "=========SENP8=========\n",
      "=========SEPT6=========\n",
      "=========SERF2=========\n",
      "=========SGF29=========\n",
      "=========SIRT1=========\n",
      "=========SLC22A13=========\n",
      "=========SLC22A14=========\n",
      "=========SLC25A3=========\n",
      "=========SLC25A5=========\n",
      "=========SLC35B2=========\n",
      "=========SLC44A2=========\n",
      "=========SLC4A2=========\n",
      "=========SLC6A10P=========\n",
      "SLC6A10P\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========SLC6A8=========\n",
      "=========SLIRP=========\n",
      "=========SLTM=========\n",
      "=========SMAD14=========\n",
      "SMAD14\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========SNAI2=========\n",
      "=========SNX1=========\n",
      "=========SNX22=========\n",
      "=========SNX5=========\n",
      "=========SOCS5=========\n",
      "=========SPARCL1=========\n",
      "=========SPDYA=========\n",
      "=========SPRED2=========\n",
      "=========SPSB2=========\n",
      "=========SRSF3=========\n",
      "=========SRSF4=========\n",
      "=========STEAP3=========\n",
      "=========STIL=========\n",
      "=========STT3B=========\n",
      "=========STX18=========\n",
      "=========SUMO3=========\n",
      "SUMO3\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========SWI5=========\n",
      "=========TACC3=========\n",
      "=========TAF4=========\n",
      "=========TAF9=========\n",
      "=========TALDO1=========\n",
      "=========TAX1BP1=========\n",
      "=========TCF4=========\n",
      "=========TERF2=========\n",
      "=========TIPRL=========\n",
      "=========TKT=========\n",
      "=========TMCO3=========\n",
      "TMCO3\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========TMED8=========\n",
      "=========TMEM127=========\n",
      "=========TMEM177=========\n",
      "TMEM177\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========TMEM199=========\n",
      "=========TMEM222=========\n",
      "=========TMEM242=========\n",
      "=========TMEM33=========\n",
      "=========TMOD2=========\n",
      "TMOD2\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n",
      "=========TMPO=========\n",
      "=========TMX1=========\n",
      "=========TOR1AIP1=========\n",
      "=========TPM3=========\n",
      "=========TPP1=========\n",
      "=========TRA2B=========\n",
      "=========TRAPPC2L=========\n",
      "=========TRIM23=========\n",
      "=========TRIM28=========\n",
      "=========TRMT61B=========\n",
      "=========TTC7B=========\n",
      "=========TUBB4B=========\n",
      "=========UACA=========\n",
      "=========UBA52=========\n",
      "=========UBE2D3-AS1=========\n",
      "UBE2D3-AS1\tOrthoDBQueryError\t0\tNo OrthoDB results for query\n",
      "=========UBE2G1=========\n",
      "=========UBE2Q2=========\n",
      "=========UGGT2=========\n",
      "=========UHMK1=========\n",
      "=========UQCRC2=========\n",
      "=========USP16=========\n",
      "=========USP3=========\n",
      "=========USPL1=========\n",
      "=========UTP18=========\n",
      "=========VAMP7=========\n",
      "=========VEGFD=========\n",
      "=========VMP1=========\n",
      "=========VPS28=========\n",
      "=========WDR48=========\n",
      "=========WTAP=========\n",
      "WTAP\tSequenceDataError\t6\tNo AGS NCBI sequences available.\n",
      "\n",
      "=========YIPF3=========\n",
      "=========YPEL5=========\n",
      "=========YWHAB=========\n",
      "=========ZBED4=========\n",
      "=========ZBTB44=========\n",
      "=========ZC3H14=========\n",
      "=========ZNF106=========\n",
      "=========ZNF200=========\n",
      "=========ZNF207=========\n",
      "=========ZNF410=========\n",
      "=========ZNF512=========\n",
      "=========ZNF91=========\n",
      "ZNF91\tSequenceDataError\t4\tTest Species has no reference sequence in input (but a record is present in unfiltered ODB query)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>MSA Position</th>\n",
       "      <th>Test Species Position</th>\n",
       "      <th>Test Variant</th>\n",
       "      <th>Test Variant Instances</th>\n",
       "      <th>AGS Variant</th>\n",
       "      <th>AGS 13LGS Consensus</th>\n",
       "      <th>Outgroup Variant</th>\n",
       "      <th>Outgroup Variant Instances</th>\n",
       "      <th>Aligned Sequences</th>\n",
       "      <th>Gap Fraction</th>\n",
       "      <th>JSD</th>\n",
       "      <th>JSD Z-Score</th>\n",
       "      <th>Test vs Outgroup Blosum62</th>\n",
       "      <th>Outgroup Pairwise Blosum62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>True</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876198</td>\n",
       "      <td>0.542996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>61</td>\n",
       "      <td>47</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.195221</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>True</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845023</td>\n",
       "      <td>0.378155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>68</td>\n",
       "      <td>54</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871565</td>\n",
       "      <td>0.518499</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>True</td>\n",
       "      <td>H</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916058</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789534</td>\n",
       "      <td>0.084753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>193</td>\n",
       "      <td>171</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>True</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>196</td>\n",
       "      <td>174</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>207</td>\n",
       "      <td>185</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.195221</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>296</td>\n",
       "      <td>274</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810426</td>\n",
       "      <td>0.195221</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>300</td>\n",
       "      <td>278</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845023</td>\n",
       "      <td>0.378155</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>540</td>\n",
       "      <td>501</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716704</td>\n",
       "      <td>-0.300348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>549</td>\n",
       "      <td>510</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.727076</td>\n",
       "      <td>-0.245507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>575</td>\n",
       "      <td>535</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765083</td>\n",
       "      <td>-0.044537</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>3.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AAAS</td>\n",
       "      <td>576</td>\n",
       "      <td>536</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633790</td>\n",
       "      <td>-0.738765</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.918751</td>\n",
       "      <td>1.130862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.876198</td>\n",
       "      <td>0.671140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.789534</td>\n",
       "      <td>-0.265121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.869273</td>\n",
       "      <td>0.596326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.243313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "      <td>L</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.441896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.789534</td>\n",
       "      <td>-0.265121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.243313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "      <td>L</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.441896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.918751</td>\n",
       "      <td>1.130862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>False</td>\n",
       "      <td>W</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>1.442105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABHD17C</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "      <td>L</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>-0.441896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-3.581388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798892</td>\n",
       "      <td>0.137430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>V</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.193377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>155</td>\n",
       "      <td>152</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>True</td>\n",
       "      <td>R</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853638</td>\n",
       "      <td>0.403197</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ZNF512</td>\n",
       "      <td>584</td>\n",
       "      <td>581</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871555</td>\n",
       "      <td>0.490172</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12562 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene MSA Position Test Species Position Test Variant  \\\n",
       "0      AAAS           18                    18            Q   \n",
       "1      AAAS           30                    30            D   \n",
       "2      AAAS           58                    44            D   \n",
       "3      AAAS           61                    47            I   \n",
       "4      AAAS           64                    50            P   \n",
       "5      AAAS           65                    51            N   \n",
       "6      AAAS           68                    54            L   \n",
       "7      AAAS           77                    63            Q   \n",
       "8      AAAS           78                    64            S   \n",
       "9      AAAS          193                   171            Q   \n",
       "10     AAAS          196                   174            T   \n",
       "11     AAAS          207                   185            I   \n",
       "12     AAAS          296                   274            I   \n",
       "13     AAAS          300                   278            I   \n",
       "14     AAAS          540                   501            S   \n",
       "15     AAAS          549                   510            -   \n",
       "16     AAAS          575                   535            T   \n",
       "17     AAAS          576                   536            L   \n",
       "0   ABHD17C            8                     1            -   \n",
       "1   ABHD17C            9                     1            -   \n",
       "2   ABHD17C           10                     1            -   \n",
       "3   ABHD17C           11                     1            -   \n",
       "4   ABHD17C           12                     1            -   \n",
       "5   ABHD17C           13                     1            -   \n",
       "6   ABHD17C           14                     1            -   \n",
       "7   ABHD17C           15                     1            -   \n",
       "8   ABHD17C           16                     1            -   \n",
       "9   ABHD17C           17                     1            -   \n",
       "10  ABHD17C           18                     1            -   \n",
       "11  ABHD17C           19                     1            -   \n",
       "..      ...          ...                   ...          ...   \n",
       "13   ZNF512           43                    43            D   \n",
       "14   ZNF512           44                    44            S   \n",
       "15   ZNF512           45                    45            F   \n",
       "16   ZNF512           46                    46            L   \n",
       "17   ZNF512           47                    47            S   \n",
       "18   ZNF512           48                    48            H   \n",
       "19   ZNF512           49                    49            L   \n",
       "20   ZNF512           50                    50            H   \n",
       "21   ZNF512           51                    51            S   \n",
       "22   ZNF512           52                    52            A   \n",
       "23   ZNF512           53                    53            T   \n",
       "24   ZNF512           54                    54            E   \n",
       "25   ZNF512           55                    55            P   \n",
       "26   ZNF512           56                    56            M   \n",
       "27   ZNF512           57                    57            H   \n",
       "28   ZNF512           58                    58            A   \n",
       "29   ZNF512           59                    59            E   \n",
       "30   ZNF512           60                    60            N   \n",
       "31   ZNF512           61                    61            R   \n",
       "32   ZNF512           62                    62            T   \n",
       "33   ZNF512           63                    63            Q   \n",
       "34   ZNF512           64                    64            C   \n",
       "35   ZNF512           65                    65            L   \n",
       "36   ZNF512           66                    66            T   \n",
       "37   ZNF512           67                    67            H   \n",
       "38   ZNF512           68                    68            A   \n",
       "39   ZNF512          125                   125            G   \n",
       "40   ZNF512          129                   129            T   \n",
       "41   ZNF512          155                   152            G   \n",
       "42   ZNF512          584                   581            S   \n",
       "\n",
       "   Test Variant Instances AGS Variant AGS 13LGS Consensus Outgroup Variant  \\\n",
       "0                       1           Q                True                L   \n",
       "1                       1           D                True                S   \n",
       "2                       1           D                True                N   \n",
       "3                       1           I                True                V   \n",
       "4                       1           P                True                L   \n",
       "5                       1           N                True                T   \n",
       "6                       1           L                True                P   \n",
       "7                       1           Q                True                H   \n",
       "8                       1           S                True                G   \n",
       "9                       1           Q                True                L   \n",
       "10                      1           T                True                S   \n",
       "11                      1           I                True                V   \n",
       "12                      1           I                True                V   \n",
       "13                      1           I                True                T   \n",
       "14                      1           S                True                A   \n",
       "15                      1           -                True                G   \n",
       "16                      1           T                True                P   \n",
       "17                      1           L                True                A   \n",
       "0                       1           M               False                M   \n",
       "1                       1           N               False                N   \n",
       "2                       1           G               False                G   \n",
       "3                       1           F               False                F   \n",
       "4                       1           S               False                S   \n",
       "5                       1           L               False                L   \n",
       "6                       1           G               False                G   \n",
       "7                       1           E               False                E   \n",
       "8                       1           L               False                L   \n",
       "9                       1           C               False                C   \n",
       "10                      1           W               False                W   \n",
       "11                      1           L               False                L   \n",
       "..                    ...         ...                 ...              ...   \n",
       "13                      1           -               False                -   \n",
       "14                      1           -               False                -   \n",
       "15                      1           -               False                -   \n",
       "16                      1           -               False                -   \n",
       "17                      1           -               False                -   \n",
       "18                      1           -               False                -   \n",
       "19                      1           -               False                -   \n",
       "20                      1           -               False                -   \n",
       "21                      1           -               False                -   \n",
       "22                      1           -               False                -   \n",
       "23                      1           -               False                -   \n",
       "24                      1           -               False                -   \n",
       "25                      1           -               False                -   \n",
       "26                      1           -               False                -   \n",
       "27                      1           -               False                -   \n",
       "28                      1           -               False                -   \n",
       "29                      1           -               False                -   \n",
       "30                      1           -               False                -   \n",
       "31                      1           -               False                -   \n",
       "32                      1           -               False                -   \n",
       "33                      1           -               False                -   \n",
       "34                      1           -               False                -   \n",
       "35                      1           -               False                -   \n",
       "36                      1           -               False                -   \n",
       "37                      1           -               False                -   \n",
       "38                      1           -               False                -   \n",
       "39                      1           G                True                A   \n",
       "40                      1           T                True                V   \n",
       "41                      1           G                True                R   \n",
       "42                      1           S                True                P   \n",
       "\n",
       "   Outgroup Variant Instances Aligned Sequences  Gap Fraction       JSD  \\\n",
       "0                          10                11      0.000000  0.773172   \n",
       "1                          10                11      0.000000  0.836597   \n",
       "2                          10                11      0.000000  0.876198   \n",
       "3                          10                11      0.000000  0.810426   \n",
       "4                          10                11      0.000000  0.773172   \n",
       "5                          10                11      0.000000  0.845023   \n",
       "6                          10                11      0.000000  0.871565   \n",
       "7                          10                11      0.000000  0.916058   \n",
       "8                          10                11      0.000000  0.789534   \n",
       "9                          10                11      0.000000  0.773172   \n",
       "10                         10                11      0.000000  0.836597   \n",
       "11                         10                11      0.000000  0.810426   \n",
       "12                         10                11      0.000000  0.810426   \n",
       "13                         10                11      0.000000  0.845023   \n",
       "14                          8                11      0.000000  0.716704   \n",
       "15                          9                11      0.090909  0.727076   \n",
       "16                          7                11      0.000000  0.765083   \n",
       "17                          7                11      0.000000  0.633790   \n",
       "0                           9                10      0.100000  0.918751   \n",
       "1                           9                10      0.100000  0.876198   \n",
       "2                           9                10      0.100000  0.789534   \n",
       "3                           9                10      0.100000  0.869273   \n",
       "4                           9                10      0.100000  0.836597   \n",
       "5                           9                10      0.100000  0.773172   \n",
       "6                           9                10      0.100000  0.789534   \n",
       "7                           9                10      0.100000  0.836597   \n",
       "8                           9                10      0.100000  0.773172   \n",
       "9                           9                10      0.100000  0.918751   \n",
       "10                          9                10      0.100000  0.947560   \n",
       "11                          9                10      0.100000  0.773172   \n",
       "..                        ...               ...           ...       ...   \n",
       "13                          8                 9      0.888889  0.032832   \n",
       "14                          8                 9      0.888889  0.032832   \n",
       "15                          8                 9      0.888889  0.032832   \n",
       "16                          8                 9      0.888889  0.032832   \n",
       "17                          8                 9      0.888889  0.032832   \n",
       "18                          8                 9      0.888889  0.032832   \n",
       "19                          8                 9      0.888889  0.032832   \n",
       "20                          8                 9      0.888889  0.032832   \n",
       "21                          8                 9      0.888889  0.032832   \n",
       "22                          8                 9      0.888889  0.032832   \n",
       "23                          8                 9      0.888889  0.032832   \n",
       "24                          8                 9      0.888889  0.032832   \n",
       "25                          8                 9      0.888889  0.032832   \n",
       "26                          8                 9      0.888889  0.032832   \n",
       "27                          8                 9      0.888889  0.032832   \n",
       "28                          8                 9      0.888889  0.032832   \n",
       "29                          8                 9      0.888889  0.032832   \n",
       "30                          8                 9      0.888889  0.032832   \n",
       "31                          8                 9      0.888889  0.032832   \n",
       "32                          8                 9      0.888889  0.032832   \n",
       "33                          8                 9      0.888889  0.032832   \n",
       "34                          8                 9      0.888889  0.032832   \n",
       "35                          8                 9      0.888889  0.032832   \n",
       "36                          8                 9      0.888889  0.032832   \n",
       "37                          8                 9      0.888889  0.032832   \n",
       "38                          8                 9      0.888889  0.032832   \n",
       "39                          8                 9      0.000000  0.798892   \n",
       "40                          8                 9      0.000000  0.810417   \n",
       "41                          8                 9      0.000000  0.853638   \n",
       "42                          8                 9      0.000000  0.871555   \n",
       "\n",
       "    JSD Z-Score  Test vs Outgroup Blosum62  Outgroup Pairwise Blosum62  \n",
       "0     -0.001767                       -2.0                    4.000000  \n",
       "1      0.333600                        0.0                    4.000000  \n",
       "2      0.542996                        1.0                    6.000000  \n",
       "3      0.195221                        3.0                    4.000000  \n",
       "4     -0.001767                       -3.0                    4.000000  \n",
       "5      0.378155                        0.0                    5.000000  \n",
       "6      0.518499                       -3.0                    7.000000  \n",
       "7      0.753762                        0.0                    8.000000  \n",
       "8      0.084753                        0.0                    6.000000  \n",
       "9     -0.001767                       -2.0                    4.000000  \n",
       "10     0.333600                        1.0                    4.000000  \n",
       "11     0.195221                        3.0                    4.000000  \n",
       "12     0.195221                        3.0                    4.000000  \n",
       "13     0.378155                       -1.0                    5.000000  \n",
       "14    -0.300348                        1.0                    2.600000  \n",
       "15    -0.245507                        NaN                    4.400000  \n",
       "16    -0.044537                       -0.4                    3.066667  \n",
       "17    -0.738765                       -0.6                    1.955556  \n",
       "0      1.130862                        NaN                    5.000000  \n",
       "1      0.671140                        NaN                    6.000000  \n",
       "2     -0.265121                        NaN                    6.000000  \n",
       "3      0.596326                        NaN                    6.000000  \n",
       "4      0.243313                        NaN                    4.000000  \n",
       "5     -0.441896                        NaN                    4.000000  \n",
       "6     -0.265121                        NaN                    6.000000  \n",
       "7      0.243313                        NaN                    5.000000  \n",
       "8     -0.441896                        NaN                    4.000000  \n",
       "9      1.130862                        NaN                    9.000000  \n",
       "10     1.442105                        NaN                   11.000000  \n",
       "11    -0.441896                        NaN                    4.000000  \n",
       "..          ...                        ...                         ...  \n",
       "13    -3.581388                        NaN                         NaN  \n",
       "14    -3.581388                        NaN                         NaN  \n",
       "15    -3.581388                        NaN                         NaN  \n",
       "16    -3.581388                        NaN                         NaN  \n",
       "17    -3.581388                        NaN                         NaN  \n",
       "18    -3.581388                        NaN                         NaN  \n",
       "19    -3.581388                        NaN                         NaN  \n",
       "20    -3.581388                        NaN                         NaN  \n",
       "21    -3.581388                        NaN                         NaN  \n",
       "22    -3.581388                        NaN                         NaN  \n",
       "23    -3.581388                        NaN                         NaN  \n",
       "24    -3.581388                        NaN                         NaN  \n",
       "25    -3.581388                        NaN                         NaN  \n",
       "26    -3.581388                        NaN                         NaN  \n",
       "27    -3.581388                        NaN                         NaN  \n",
       "28    -3.581388                        NaN                         NaN  \n",
       "29    -3.581388                        NaN                         NaN  \n",
       "30    -3.581388                        NaN                         NaN  \n",
       "31    -3.581388                        NaN                         NaN  \n",
       "32    -3.581388                        NaN                         NaN  \n",
       "33    -3.581388                        NaN                         NaN  \n",
       "34    -3.581388                        NaN                         NaN  \n",
       "35    -3.581388                        NaN                         NaN  \n",
       "36    -3.581388                        NaN                         NaN  \n",
       "37    -3.581388                        NaN                         NaN  \n",
       "38    -3.581388                        NaN                         NaN  \n",
       "39     0.137430                        0.0                    4.000000  \n",
       "40     0.193377                        0.0                    4.000000  \n",
       "41     0.403197                       -2.0                    5.000000  \n",
       "42     0.490172                       -1.0                    7.000000  \n",
       "\n",
       "[12562 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Modified input schema - use pre-aligned AGS to 13LGS sequences\n",
    "\n",
    "# #Input parsing and background distribution information\n",
    "DEFAULT_SPECIES_PATH = \"config/v10_0_species.txt\"\n",
    "aas, blosum62_bg, blos_df, sim_matrix = gen_blos_df()\n",
    "config = parse_config()\n",
    "run_name = config[\"RunName\"]\n",
    "create_run_directory(run_name)\n",
    "# spec_list, spec_hc = parse_species(DEFAULT_SPECIES_PATH)\n",
    "# write_run_params_file(config, DEFAULT_SPECIES_PATH, spec_hc)\n",
    "genes_file = config[\"GenesFile\"]\n",
    "gene_list = parse_genes(genes_file)\n",
    "tax_table = odb_tablev10(spec_list)\n",
    "\n",
    "UNIQUE_THRESH = 0.1\n",
    "# DROP_SPEC_LIST = [\"10141_0\",\"13616_0\",\"9258_0\",\"9483_0\",\"9544_0\",\"9598_0\",\"9685_0\",\"43346_0\",\"246437_0\",\"9925_0\",\\\n",
    "#                  \"9940_0\",\"9646_0\",\"74533_0\",\"9365_0\",\"9785_0\",\"34839_0\"]\n",
    "\n",
    "# #Config Settings invariant of gene; creation of subfolders for run\n",
    "test_species_name = config[\"TestSpecies\"]\n",
    "errors_fpath = '{0}/summary/errors.tsv'.format(run_name)\n",
    "seq_qc_fpath = '{0}/summary/seq_QC.tsv'.format(run_name)\n",
    "AGS_aln_base_dir = \"{0}/allspec_AGS_alignments\".format(run_name)\n",
    "output_base_dir = \"{0}/output\".format(run_name)\n",
    "\n",
    "if os.path.exists(errors_fpath):\n",
    "    check_errors = True\n",
    "    errors_df = pd.read_csv(errors_fpath,delimiter=\"\\t\",index_col=\"gene\")\n",
    "    errors_df = errors_df.loc[~(errors_df[\"error_type\"]==\"SequenceAnalysisError\"),:]\n",
    "    error_genes = errors_df.index\n",
    "    display(errors_df)\n",
    "else:\n",
    "    check_errors = False\n",
    "# #Acquire input\n",
    "# valid_searches, failed_searches = download_input_data(gene_list,tax_table,config) \n",
    "# #Run analysis for each gene in genes list\n",
    "# window_calculations = False\n",
    "OVERWRITE_ANALYSIS = False\n",
    "overall_summary_cols = [\"Gene\",\"MSA Position\",\"Test Species Position\",\"Test Variant\",\"Test Variant Instances\", \\\n",
    "                \"AGS Variant\", \"AGS 13LGS Consensus\",\"Outgroup Variant\", \"Outgroup Variant Instances\",\\\n",
    "                \"Aligned Sequences\", \"Gap Fraction\", \"JSD\",\"JSD Z-Score\", \\\n",
    "                 \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "updated_summary_ordered_cols = [\"Test Species Position\",\"Test Variant\",\"Test Variant Instances\", \\\n",
    "                                \"AGS Variant\", \"AGS 13LGS Consensus\",\"Outgroup Variant\", \"Outgroup Variant Instances\",\\\n",
    "                                \"Aligned Sequences\", \"Gap Fraction\", \"JSD\",\"JSD Z-Score\", \\\n",
    "                                 \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "numeric_cols = [\"Gap Fraction\",\"JSD\",\"JSD Z-Score\", \\\n",
    "                \"Test vs Outgroup Blosum62\", \"Outgroup Pairwise Blosum62\"]\n",
    "# dtype_specification = zip(numeric_cols,[np.float64]*len(numeric_cols))\n",
    "overall_summary = pd.DataFrame(columns=overall_summary_cols)\n",
    "for col in numeric_cols:\n",
    "    overall_summary[col] = overall_summary[col].astype(np.float64)\n",
    "no_uniques = []\n",
    "for gene_name in gene_list[:]:\n",
    "    empty_directory(\"tmp\")\n",
    "    print(\"=========\"+gene_name+\"=========\")\n",
    "    \n",
    "    AGS_aln_gene_dir = \"{0}/{1}\".format(AGS_aln_base_dir,gene_name)\n",
    "    output_gene_dir = \"{0}/{1}\".format(AGS_aln_base_dir,gene_name)\n",
    "    AGS_MSA_fpath = \"{0}/{1}_MSA.fasta\".format(AGS_aln_gene_dir,gene_name)\n",
    "    \n",
    "    all_records_fpath = \"{0}/{1}_records.csv\".format(AGS_aln_gene_dir,gene_name)\n",
    "    prev_summary_fpath = \"{0}/{1}_summary.csv\".format(AGS_aln_gene_dir,gene_name)\n",
    "    updated_summary_fpath = \"{0}/{1}_AGS_summary.csv\".format(AGS_aln_gene_dir,gene_name)\n",
    "    \n",
    "    if check_errors and gene_name in error_genes:#error_genes.str.contains(gene_name).any():\n",
    "        error_row = errors_df.loc[gene_name,:]\n",
    "        error_type, error_code, error_str = error_row.values\n",
    "        print(\"{0}\\t{1}\\t{2}\\t{3}\".format(gene_name,error_type,error_code,error_str))\n",
    "    elif not os.path.exists(AGS_MSA_fpath):\n",
    "        AGS_SD_error = SequenceDataError(6,\"No AGS NCBI sequences available.\")\n",
    "        write_errors(errors_fpath,gene_name,AGS_SD_error)\n",
    "        continue\n",
    "    elif os.path.exists(updated_summary_fpath) and not OVERWRITE_ANALYSIS:\n",
    "        summary_df = read_summary_output(updated_summary_fpath,gene_name)\n",
    "        overall_summary = overall_summary.append(summary_df,sort=False)\n",
    "    else:\n",
    "        AGS_MSA_srs = fasta_to_srs(AGS_MSA_fpath)\n",
    "        AGS_MSA_df = align_srs_to_df(AGS_MSA_srs)\n",
    "        all_records_df = pd.read_csv(all_records_fpath,index_col=\"Unnamed: 0\")\n",
    "        \n",
    "        AGS_idx = AGS_MSA_df.index[AGS_MSA_df.index.str.contains('XP_')][0]\n",
    "        LGS_idx = AGS_MSA_df.index[AGS_MSA_df.index.str.contains('43179_')][0]\n",
    "        AGS_row = AGS_MSA_df.loc[AGS_idx,:]\n",
    "        ODB_MSA_df = AGS_MSA_df.drop(index=AGS_idx)\n",
    "        n, align_len = len(ODB_MSA_df.index), len(ODB_MSA_df.columns)\n",
    "#         #Unique substitutions must be present in < UNIQUE_THRESH*100 % of sequences (or min of 1) \n",
    "        sub_freq_threshold = max(int(n*UNIQUE_THRESH), 1)\n",
    "        uniques = find_uniques(ODB_MSA_df,sub_freq_threshold,LGS_idx,display_uniques=False)\n",
    "        if len(uniques.columns) == 0:\n",
    "#             write_output3(gene_name,run_name,final_records_df)\n",
    "            no_uniques.append(gene_name)\n",
    "            continue\n",
    "        else:\n",
    "            align_nd = ODB_MSA_df.values\n",
    "            seq_weights = calculate_sequence_weights(align_nd,aas)\n",
    "            #Unique substitution identification, metrics calculations and individual gene output writing\n",
    "            gap_dict, unique_gaps, unique_subs = species_gaps_dict(ODB_MSA_df)\n",
    "            jsd_srs, jsd_zscores, gap_positions = generate_jsd_series(LGS_idx,ODB_MSA_df,align_len,aas,blosum62_bg)\n",
    "            sw_metrics = calc_sw_metrics(jsd_srs, uniques, gap_positions,align_len, config)\n",
    "#             if window_calculations:\n",
    "#                 summary_df = summary_table(final_align_df,sw_metrics,test_species_id,blos_df,display_summary)\n",
    "#             else:\n",
    "            summary_df = summary_table2(ODB_MSA_df,sw_metrics,LGS_idx,blos_df,display_summary=False)\n",
    "            write_output4(all_records_fpath,prev_summary_fpath,summary_df=summary_df)\n",
    "\n",
    "            MSA_pos_idx = summary_df.index\n",
    "            AGS_var_srs = AGS_row.loc[MSA_pos_idx]\n",
    "            AGS_13LGS_consensus_srs = AGS_var_srs==summary_df[\"Test Variant\"]\n",
    "            updated_summary_df = summary_df.copy()\n",
    "            updated_summary_df.loc[:,\"AGS Variant\"] = AGS_var_srs\n",
    "            updated_summary_df.loc[:,\"AGS 13LGS Consensus\"] = AGS_13LGS_consensus_srs\n",
    "            \n",
    "            updated_summary_df = updated_summary_df[updated_summary_ordered_cols]\n",
    "            write_output4(all_records_fpath,updated_summary_fpath,summary_df=updated_summary_df)\n",
    "            updated_summary_df.reset_index(drop=False,inplace=True)\n",
    "            if not \"Gene\" in updated_summary_df.columns:\n",
    "                updated_summary_df.insert(0,\"Gene\",[gene_name]*len(updated_summary_df))\n",
    "            overall_summary = overall_summary.append(updated_summary_df,sort=False)\n",
    "\n",
    "display(overall_summary)\n",
    "overall_summary_path = run_name+\"/summary/summary.csv\"\n",
    "overall_summary.to_csv(overall_summary_path,float_format='%.5f')\n",
    "# plt.scatter(x=overall_summary[\"JSD\"],y=overall_summary[\"Test vs Outgroup Blosum62\"],alpha=0.2)\n",
    "# plt.xlabel(\"Position JSD\")\n",
    "# plt.ylabel(\"Average Test Species vs Outgroup Blosum62\")\n",
    "# plt.title(\"Distribution of JSD/ Blosum for all input unique subs\")\n",
    "# plt.savefig(run_name+\"/summary/summary_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(tax_table)\n",
    "# print(len(tax_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TEST CELL\n",
    "# # print(failed_searches)\n",
    "# fasta_path,fasta_df, ref_index = read_query_input(\"ATP5G2\", \"cDNA_screen_ATP5G\")\n",
    "# # display(fasta_df)\n",
    "# tsv_path = run_name+\"/input/\"+gene_name+\".tsv\"\n",
    "# fasta_path = run_name+\"/input/\"+gene_name+\".fasta\"\n",
    "# tsv_df = pd.read_csv(tsv_path,delimiter='\\t')\n",
    "# tsv_df.set_index(keys=\"int_prot_id\",drop=True,inplace=True)#drop=False)\n",
    "# fasta_seqs = SeqIO.parse(open(fasta_path),'fasta')\n",
    "# fasta_df = pd.DataFrame(columns=[\"id\",\"pubgene_id\",\"desc\",\"aaseq\",\"length(aa)\"])\n",
    "# #Generate DataFrame of all reference sequences to use for input filtering. See above \n",
    "# #methods for implementation.\n",
    "# ref_ids, gc_name = find_ref_seqs(gene_name,tsv_df,errors_fpath)\n",
    "# print(ref_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "gene_list2 = parse_genes(genes_file)\n",
    "print(len(gene_list2))\n",
    "\n",
    "AGS_aln_base_dir = \"{0}/allspec_AGS_alignments\".format(run_name)\n",
    "complete_analysis = []\n",
    "\n",
    "for gene_name in gene_list2:\n",
    "    AGS_gene_dir = \"{0}/{1}\".format(AGS_aln_base_dir,gene_name)\n",
    "    if os.path.exists(AGS_gene_dir):\n",
    "        complete_analysis.append(gene_name)\n",
    "print(len(complete_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
